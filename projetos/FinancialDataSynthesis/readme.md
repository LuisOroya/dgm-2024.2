# `S√≠ntese de Dados Financeiros`
==============================

# `Financial Data Synthesis`
==============================
## Link dos slides:
https://docs.google.com/presentation/d/1eOmgRpkQeXU1htM_7Gq66HRcn2CPZ7iB/edit?pli=1#slide=id.p1

Apresenta√ß√£o
==============================
<p align="justify">
O presente projeto foi originado no contexto das atividades da disciplina de p√≥s-gradua√ß√£o IA376N - Deep Learning aplicado a S√≠ntese de Sinais, oferecida no segundo semestre de 2024, na Unicamp, sob supervis√£o da Profa. Dra. Paula Dornhofer Paro Costa, do Departamento de Engenharia de Computa√ß√£o e Automa√ß√£o (DCA) da Faculdade de Engenharia El√©trica e de Computa√ß√£o (FEEC).
</p>

 |Nome  | RA | Curso|
 |--|--|--|
 |Jos√© Carlos Ferreira  | 170860  | Eng. El√©trica |
 |Byron Alejandro Acu√±a Acurio  | 209428  | Eng. El√©trica |

## Resumo (Abstract)
<p align="justify">
Neste trabalho foi testada a capacidade de dois modelos generativos baseadas em GANS e Transformers na previs√£o do pre√ßo da a√ß√£o da empresa Apple, considerando uma
condi√ß√£o de evento extremo neste caso o Covid19 no ano 2020. A Rede Adversarial Generativa (GAN) foi desenvolvida usando Unidades Recorrentes Fechadas (GRU) como um gerador que insere o pre√ßo hist√≥rico das a√ß√µes e gera a previs√£o do pre√ßo futuro (no d√≠a seguente) das a√ß√µes e uma Rede Neural Convolucional (CNN) como um discriminador para discriminar entre o pre√ßo real das a√ß√µes e o pre√ßo das a√ß√µes gerado. Para estimar o pre√ßo da a√ß√£o foi usada 36 caracter√≠sticas como √≠ndice S&P 500, √≠ndice NASDAQ Composite, √≠ndice U.S. √çndice do d√≥lar, etc. Comparamos os resultados do nosso modelo GAN e Transformer com modelos de aprendizado profundo baseados em LSTM e GRU. O modelo generativo apresenta um melhor desempenho em eventos extremos.
</p>

## Introdu√ß√£o
<p align="justify">
Nosso projeto foca na gera√ß√£o de dados financeiros sint√©ticos realistas, especificamente sobre o pre√ßo da a√ß√£o da empressa Apple atrav√©s de duas abordagens: baseadas em GANS e Transformers.
Os dados sint√©ticos s√£o √∫teis em modelos em que a confian√ßa apenas em dados hist√≥ricos n√£o √© suficiente para construir um m√©todo robusto. Neste trabalho os experimentos foram realizados antes e depois do Covid-19, para verificar a robustez de nossos modelos generativos frente a eventos extremos.
</p>

O projeto lida com s√©ries temporais da forma:

$$ X_{1:N}  = [{ x(1), x(2), ..., x(N) }]  $$

Em que cada elemento $x(i)$ representa o pre√ßo da a√ß√£o da empressa Apple no instante $i$.

<p align="justify">
A continua√ß√£o se apresenta a serie temporal dos pre√ßos da a√ß√£o da empressa Apple, a usada data usada dos dados foi desde 2010-07-01 at√© 2020-06-30, para fazer experimentos antes e depois do Covid-19 (evento extremo)
</p>

![Time Series Visualization](img_readme/Serie_temporal.png)


Atr√°ves da incorpora√ß√£o de features relevantes, tamb√©m representados por s√©ries temporais (alinhadas √† $X_{1:N}$), buscamos gerar dados sint√©ticos que representam uma continua√ß√£o realista de $X_{1:N}$, isso √©, uma s√©rie temporal do tipo:

$$ X^{s}_{N+1:N+K}  = [{ x^{s}(N+1), x^{s}(N+2), ..., x^{s}(N+K) }]  $$

Tal que:

$$ X^{s}_{N+1:N+K}  \approx X\_{N+1:N+K}   $$



Por exemplo, se $X_{1:N}$ representa os pre√ßos da a√ß√£o da empressa Apple janeiro at√© fevereiro, $X^{s}_{N+1:N+K}$ poderia representar valores plaus√≠veis de fevereiro at√© mar√ßo no ano 2020 que iniciu o lockdown por causa do Covid 19 (Evento Extremo).

<!-- Essas representa√ß√µes realistas s√£o importantes para modelos de otimiza√ß√£o de portf√≥lios, pois podemos gerar diversos cen√°rios poss√≠veis e escolher a estrat√©gia que se sai melhor, considerando todas as possibilidades geradas. Dessa forma, o modelo de otimiza√ß√£o √© robusto e consegue bom desempenho nas mais diversas situa√ß√µes. -->
## Descri√ß√£o do Problema/Motiva√ß√£o
No setor financeiro, o acesso a dados do mundo real para an√°lise e treinamento de modelos √© limitado devido a quest√µes de privacidade e seguran√ßa. Assim os dados sint√©ticos podem ajudar a fornecer uma alternativa segura para disponibilizar esses dados para diversas organiza√ß√µes. O desenvolvimento de modelos com capacidade de prever o pre√ßo da a√ß√£o de forma precisa √© desafiador devido √† complexidade inerente desses dados. Em geral, os dados financeiros s√£o n√£o estacion√°rios e seguem distribui√ß√µes de probabilidade desconhecidas e dif√≠ceis de serem estimadas. Apesar dos avan√ßos nos algoritmos de deep learning, que conseguem capturar melhor essas complexidades, a escassez de dados financeiros dispon√≠veis tem sido um fator limitante na constru√ß√£o de m√©todos robustos. Especialmente em eventos extremos quando no hist√≥rico de dados nunca se teve um registro de um evento similar.

H√° um movimento crescente entre pesquisadores para otimizar modelos de machine learning atrav√©s da incorpora√ß√£o de dados financeiros sint√©ticos [4]. A gera√ß√£o de dados sint√©ticos permite melhorar o desempenho de m√©todos que, at√© ent√£o, apresentavam resultados insatisfat√≥rios ou eram invi√°veis na pr√°tica devido √† falta de dados, al√©m de possibilitar a simula√ß√£o de eventos raros ou extremos. 

Diversas metodologias t√™m sido estudadas. As arquiteturas da fam√≠lia Generative Adversarial Networks (GANs) t√™m mostrado bons resultados em tarefas de gera√ß√£o de imagens e, mais recentemente, est√£o sendo aplicadas na gera√ß√£o de dados financeiros sint√©ticos. Al√©m das GANs, as arquiteturas Transformers tamb√©m surgem como estruturas promissoras para a tarefa. 

A cria√ß√£o de dados financeiros que reproduzam o comportamento de dados reais √© essencial para v√°rias aplica√ß√µes, como o problema de otimiza√ß√£o de portf√≥lios. Considere um investidor com acesso a ùëõ classes de ativos. O problema de otimiza√ß√£o de portf√≥lio consiste em alocar esses ativos de modo a maximizar o retorno, escolhendo a quantidade apropriada para cada classe, enquanto mant√©m o risco do portf√≥lio dentro de um n√≠vel de toler√¢ncia predefinido. Pesquisas recentes em otimiza√ß√£o de portf√≥lios financeiros exploraram diversas abordagens para melhorar as estrat√©gias de aloca√ß√£o de ativos. A gera√ß√£o de dados sint√©ticos tem se destacado como uma boa solu√ß√£o para ampliar conjuntos de dados financeiros limitados, com estudos propondo modelos de regress√£o sint√©tica [1] e redes advers√°rias generativas condicionais modificadas [2].

Neste trabalho, focamos na gera√ß√£o de dados sint√©ticos de ativos listados em bolsas de valores (nacionais e internacionais) utilizando uma abordagem baseada em GANs e Transformers. A gera√ß√£o de dados sint√©ticos √© particularmente √∫til para capturar cen√°rios de retorno que est√£o ausentes nos dados hist√≥ricos, mas s√£o estatisticamente plaus√≠veis.


## Objetivos

O projeto tem como **objetivo principal** :

- Gerar s√©ries temporais sint√©ticas realistas de ativos financeiros.

Para o projeto, escolhemos tr√™s ativos financeiros distintos:
- **√çndice Bovespa**: pontua√ß√£o que mede o desempenho das a√ß√µes das maiores empresas listadas na bolsa de a√ß√µes brasileira (B3);
- **√çndice S&P 500**: pontua√ß√£o que mede o desempenho das 500 maiores a√ß√µes listadas na bolsa de a√ß√µes de Nova York (NYSE);
- **A√ß√µes da VALE S.A**: terceira maior empresa brasileira, com a√ß√µes negociadas na NYSE e B3;

Al√©m disso, adotamos duas abordagens distintas para gera√ß√£o dos dados:
1. Baseada na arquitetura **Transformers**;
2. Baseada na arquitetura de redes generativas adversarias **(GANs)**;

Temos como miss√£o, dado a s√©rie temporal desses ativos em determinado per√≠odo, gerar s√©ries temporais sint√©ticas plaus√≠veis que representam a continua√ß√£o das s√©ries originais.

Para medir o "realismo" das s√©ries, utilizamos diversas m√©tricas, como o teste Kolmogorov-Smirnov (KS), dist√¢ncia de Jensen-Shannon, dist√¢ncia de Wasserstein, al√©m de gr√°ficos de similaridade T-SNE bidemnsional para verificar visualmente a similaridade distribucional entre dados reais e sint√©ticos.

### Bases de Dados

|Base de Dados | Endere√ßo na Web | Resumo descritivo|
|----- | ----- | -----|
|API do Yahoo Finance| https://finance.yahoo.com | Permite o acesso a dados financeiros por meio de chamadas de API. Esses dados incluem pre√ßos de fechamento, pre√ßos m√°ximos, m√≠nimos, volume negociado. Al√©m disso, √© poss√≠vel coletar os dados considerando diferentes per√≠odos de amostragem: 2 minutos, 5 minutos, 15 minutos, 1 hora, 1 dia.|


## Metodologia e Workflow
**CASO 1: TRANSFORMERS**

A metodologia para a gera√ß√£o das s√©ries temporais sint√©ticas utilizando arquitetura Transformers pode ser resumida no seguinte passo a passo:

1. **Coleta de Dados via API do Yahoo Finance:**
   
   Atrav√©s desse API, coletamos os pre√ßos com um per√≠odo de amostragem de 2 minutos, e armazenamos em um vetor que representa a s√©rie temporal: $X\_{1:N}$.
   
   O per√≠odo de amostragem de 2 minutos foi escolhido pois √© o menor que o API disponibiliza. Optamos por realizar uma an√°lise em alta frequ√™ncia, pois as varia√ß√µes nos pre√ßos n√£o s√£o t√£o abruptas comparadas √† de uma frequ√™ncia menor (e.g. valores di√°rios). Dessa forma, o modelo consegue gerar dados dentro de uma faixa razo√°vel de valores. A figura abaixo ilustra um exemplo.
   
<div align="center">
    <img src="Valores_Vale.png" alt="Pre√ßos_Vale" title="Vale" />
    <p><em>Figura 1: Pre√ßos das a√ß√µes da Vale com um per√≠odo de amostragem de 2 minutos coletados do API do Yahoo Finance.</em></p>
</div>

2. **Extra√ß√£o de Features:**

   Para auxiliar na gera√ß√£o de dados sint√©ticos realistas, tamb√©m extraimos diversos features que ajudam a explicar o comportamento dos pre√ßos. Esses features tamb√©m s√£o s√©ries temporais, dados (cada um) por: $F\_{1:N}$. Eles possuem o mesmo n√∫mero de amostras da s√©rie temporal de pre√ßos.

Os features que se mostraram √∫teis na gera√ß√£o dos dados sint√©ticos foram:

   - Volume de a√ß√µes negociada;
   - √çndices t√©cnicos: Moving Average Convergence Divergence (MACD), Stochastic Oscillator (SO), Commodity Channel Index (CCI), Money Flow Index (MFI);
  
Os √≠ndices t√©cnicos s√£o algumas m√©tricas que podem ser calculadas a partir do pre√ßo de fechamento, pre√ßo m√°ximo e m√≠nimo, al√©m do volume de a√ß√µes negociadas. Esses √≠ndices t√©cnicos buscam capturar as tend√™ncias de movimenta√ß√£o dos pre√ßos. A figura abaixo ilustra um exemplo de um feature utilizado:

<div align="center">
    <img src="Volume_Vale.png" alt="Volume_Vale" title="Vale" />
    <p><em>Figura 2: Volume de a√ß√µes da Vale negociadas com um per√≠odo de amostragem de 2 minutos coletados do API do Yahoo Finance.</em></p>
</div>

3. **Normaliza√ß√£o dos Dados:**

   Ap√≥s a coleta dos dados e extra√ß√£o dos features, armazenamos as s√©ries temporais (do pre√ßo e dos features) em um mesmo dataframe: $D=[X\_{1:N}, F\_{1:N} ]$.
   
   Ap√≥s isso, normalizamos os valores de cada s√©rie temporal para facilitar o treinamento, utilizando as suas respectivas m√©dias e desvios padr√µes. A normaliza√ß√£o adotada foi:

$$ x_{n}(i) = \frac{x(i) - \text{m√©dia[x]}}{\text{desvio padr√£o[x]}}$$

- $x_{n}(i)$: representa o valor normalizado de uma s√©rie temporal (pre√ßo ou algum feature) no instante $i$.
-  $x(i)$: representa o valor antes da normaliza√ß√£o (pre√ßo ou algum feature) no instante $i$.
- m√©dia[x], desvio padr√£o [x] : representam a m√©dia e o desvio padr√£o associado √† s√©rie temporal dos elementos de x(i)  
   
4. **Constru√ß√£o da Rede Neural:**
   A rede neural √© um modelo baseado na arquitetura Transformer sendo utilizado para predi√ß√£o de s√©ries temporais. Ele processa sequ√™ncias de dados para predizer o valor futuro com base nas observa√ß√µes passadas. A figura abaixo ilustra o modelo, de maneira simplificada, atr√°ves de blocos:
   <div align="center">
    <img src="Arquitetura_Blocos.png" alt="Arquitetura" title="Arquitetura" />
    <p><em>Figura 3: Estrutura simplificada do modelo baseado na arquitetura Transformer. </em></p>
</div>

- **Input:**
   
   A entrada √© um dataframe D contendo a s√©rie temporal do pre√ßo $X_{1:N}$ e dos features $F\_{1:N}$.
   
- **Sequenciador das S√©ries Temporais:**
   
   As s√©ries temporais s√£o repartidas em sequ√™ncias de tamanho fixo (tam_seq) para o processamento nos blocos Transformers. Al√©m disso, associamos a cada sequ√™ncia um target, que representa o valor que desejamos prever (r√≥tulo). Para o treinamento, a rede recebe um conjunto de sequ√™ncias e os r√≥tulos correspondentes.
   
- **Layer de Input:**
   
   A entrada da rede √© um vetor multidimensional que cont√©m todas as sequ√™ncias de tamanho tam_seq para todos os features.
   
- **Embedding Layer:**

   A embedding layer √© uma camada densa que transforma os dados em um espa√ßo dimensional maior. √â √∫til para que o modelo aprenda rela√ß√µes mais complexas nos dados.

- **Positional Encoding:**

   Adiciona informa√ß√µes sobre a posi√ß√£o de cada elemento da sequ√™ncia, visto que o Transformer n√£o conhece a ordem temporal dos dados. Isso permite que o modelo saiba a ordem temporal dos dados.

- **Blocos Transformers:**

   Sequ√™ncias de blocos da arquitetura Transformer, cada bloco possui os seguintes elementos:

   - Layer MultiHead Attention: permite que o modelo se concentre em diferentes partes da sequ√™ncia para realizar a predi√ß√£o
   - Conex√£o Residual e Normaliza√ß√£o: adiciona a entrada do bloco √† sa√≠da do layer MultiHead Attention e normaliza os valores. Isso ajuda na estabiliza√ß√£o de treinamento.
   - Rede Feed-Forward: duas camadas densas com fun√ß√£o de ativa√ß√£o ReLU na primeira.
     
- **Global Average Pooling:**
    
   Reduz a sa√≠da dos blocos transformers para um vetor de tamanho fixo atrav√©s do c√°lculo da m√©dia dos valores.

- **Output Layer**:

    Camada densa que gera o valor predito. No nosso modelo, predizemos apenas um √∫nico valor por vez.

Os detalhes espec√≠ficos da constitui√ß√£o de cada bloco est√£o descritos neste link: [Detalhes_Arquitetura](docs/Arquitetura.md)

5. **Treinamento:**

Ap√≥s a constru√ß√£o do modelo, partimos para a etapa de treinamento. Nesta etapa, o nossos dados de entrada $D = [X_{1:N}, F_{1:N}]$ s√£o separados em conjunto de treinamento, valida√ß√£o e teste:

- Conjunto de treinamento: Os 70% primeiros elementos do dataset de entrada
- Conjunto de valida√ß√£o:      20% dos elementos do dataset
- Conjunto de teste:       Os 10% √∫ltimos elementos do dataset de entrada

Por exemplo, se o dataset de entrada s√£o s√©ries temporais com 1000 elementos, ent√£o os 700 primeiros elementos s√£o utilizados para treinamento, os 200 elementos seguintes para valida√ß√£o, e os √∫ltimos 100 para teste. Foi importante garantir que os dados estejam ordenados, pois apresentam depend√™ncias temporais.

Conforme explicado no bloco de sequenciamento das s√©ries temporais, os dados s√£o transformados em sequ√™ncias de tamanho fixo. No nosso caso, observamos que sequ√™ncias com 24 instantes de tempo consecutivos apresentaram os melhores resultados. Logo, o modelo recebe como entrada sequ√™ncias com 24 elementos consecutivos e o r√≥tulo associado, que no caso, seria o 25¬∫ elemento.

Ou seja, dado os √∫ltimos 24 pre√ßos (e features), o modelo tentar√° prever o 25¬∫ pre√ßo, e a verifica√ß√£o da qualidade da solu√ß√£o ser√° dado pela compara√ß√£o com o valor do r√≥tulo que √© o valor real do 25¬∫ pre√ßo.

Para o treinamento, foi utilizado os seguintes hiperpar√¢metros:
- Otimizador: Adaptative Moment Estimator (Adam);
- Fun√ß√£o de perda: Mean Absolute Error;
-  Batch size: 128;
-  N√∫mero de √©pocas: 200 (com early stopping);

  A escolha dos melhores par√¢metros foi baseado na perda observada para o conjunto de valida√ß√£o.

  6. **Infer√™ncia:**

Ap√≥s o treinamento, utilizamos o modelo para prever os pontos do conjunto de teste e comparamos com os respectivos r√≥tulos associados.

A figura abaixo ilustra o workflow:

 <div align="center">
    <img src="Workflow.png" alt="Workflow" title="Workflow" />
    <p><em>Figura 4: Workflow contemplando o processo de treinamento e infer√™ncia. </em></p>
</div>

## Experimentos, Resultados e Discuss√£o dos Resultados




### Artigos de Refer√™ncia
Os principais artigos que o grupo j√° identificou como base para estudo e planejamento do projeto s√£o:

- **Pagnocelli. (2022)**: "A Synthetic Data-Plus-Features Driven Approach for Portfolio Optimization" [5].
  
- **Pe√±a et al. (2024)**: "A modified CTGAN-plus-features-based method for optimal asset allocation" [2].

-  **F.Eckerli, J.Osterrieder.** "Generative Adversarial Networks in finance: an overview" [3]. 

### Ferramentas
Existem diversas bibliotecas Python dispon√≠veis para gera√ß√£o de dados sint√©ticos, cada uma com suas capacidades e recursos distintos. Neste trabalho exploraremos as seguintes bibliotecas CTGAN  e Synthetic Data Vault (SDV).

- **CTGAN** √© uma cole√ß√£o de geradores de dados sint√©ticos baseados em Deep Learning para dados de tabela √∫nica, que s√£o capazes de aprender com dados reais e gerar dados sint√©ticos com alta fidelidade. 

- **SDV (Synthetic Data Vault)** O pacote √© focado na gera√ß√£o e avalia√ß√£o de dados sint√©ticos tabulares, multitabelas e s√©ries temporais. Aproveitando uma combina√ß√£o de modelos de aprendizado de m√°quina, o SDV fornece recursos e s√≠ntese de dados, ao mesmo tempo em que garante que os conjuntos de dados gerados se assemelhem aos dados originais em estrutura e propriedades estat√≠sticas. 

- **Python** com bibliotecas como `PyTorch` e `scikit-learn` para implementar os modelos generativos e realizar a s√≠ntese de dados.
   
- **Colab** para colabora√ß√£o e execu√ß√£o de experimentos em ambientes com suporte a GPU.
  
- **Pandas** e **NumPy** para manipula√ß√£o de dados tabulares.

### Proposta de Avalia√ß√£o
Para a avalia√ß√£o da qualidade dos nossos geradores de dados sint√©ticos, al√©m dos fatos estilizados, vamos considerar v√°rias outras m√©tricas utilizando amostras reais e sint√©ticas. As m√©tricas de avalia√ß√£o que pretendemos utilizar s√£o:

Compara√ß√£o entre as distribui√ß√µes sint√©ticos e hist√≥ricos usando m√©tricas que capturam os aspectos distribucionais dos dados sint√©ticos com rela√ß√£o √†s amostras reais. Neste caso vamos usar o teste Kolmogorov-Smirnov (KS), teste Qui-quadrado (CS) que medem a similaridade para vari√°veis ‚Äã‚Äãcont√≠nuas e categ√≥ricas (colunas) respectivamente. A medidas de diverg√™ncia distribucional como dist√¢ncia de Jensen-Shannon, Discrep√¢ncia M√©dia M√°xima (MMD) e dist√¢ncia de Wasserstein. Gr√°ficos de similaridade T-SNE bidemnsional para verificar visualmente a similaridade distribucional entre dados reais e sint√©ticos. 

## Conclus√£o
Por fim, a principal dificuldade do projeto ser√° gerar os dados financeiros sint√©ticos realistas. Abordaremos diversas estrat√©gias que v√£o desde o pr√©-processamento dos dados, ajustes nos hiperpar√¢metros das GANs e o emprego de m√©tricas eficientes.
 
## Refer√™ncias Bibliogr√°ficas
[1] Li, Gaorong, Lei Huang, Jin Yang, and Wenyang Zhang.  
"A synthetic regression model for large portfolio allocation."  
*Journal of Business & Economic Statistics* 40, no. 4 (2022): 1665-1677.

[2] Pe√±a, Jos√©-Manuel, Fernando Su√°rez, Omar Larr√©, Domingo Ram√≠rez, and Arturo Cifuentes. 
"A modified CTGAN-plus-features-based method for optimal asset allocation".
" Quantitative Finance 24, no. 3-4 (2024): 465-479".

[3] https://mba.tuck.dartmouth.edu/pages/faculty/ken.french/data_library.html

[4] F.Eckerli, J.Osterrieder.
" Generative Adversarial Networks in finance: an overview."

[5]- Bernardo K. Pagnoncelli, Arturo Cifuentes, Domingo Ram√≠rez and Hamed Rahimian.
 "A Synthetic Data-Plus-Features Driven Approach for Portfolio Optimization".
 Computational Economics, 2023, Volume 62, Number 1, Page 187.


Project Organization
------------

    ‚îú‚îÄ‚îÄ LICENSE
    ‚îú‚îÄ‚îÄ Makefile           <- Makefile with commands like `make data` or `make train`
    ‚îú‚îÄ‚îÄ README.md          <- The top-level README for developers using this project.
    ‚îú‚îÄ‚îÄ data
    ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ external       <- Data from third party sources.
    ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ interim        <- Intermediate data that has been transformed.
    ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ processed      <- The final, canonical data sets for modeling.
    ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ raw            <- The original, immutable data dump.
    ‚îÇ
    ‚îú‚îÄ‚îÄ docs               <- A default Sphinx project; see sphinx-doc.org for details
    ‚îÇ
    ‚îú‚îÄ‚îÄ models             <- Trained and serialized models, model predictions, or model summaries
    ‚îÇ
    ‚îú‚îÄ‚îÄ notebooks          <- Jupyter notebooks. Naming convention is a number (for ordering),
    ‚îÇ                         the creator's initials, and a short `-` delimited description, e.g.
    ‚îÇ                         `1.0-jqp-initial-data-exploration`.
    ‚îÇ
    ‚îú‚îÄ‚îÄ references         <- Data dictionaries, manuals, and all other explanatory materials.
    ‚îÇ
    ‚îú‚îÄ‚îÄ reports            <- Generated analysis as HTML, PDF, LaTeX, etc.
    ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ figures        <- Generated graphics and figures to be used in reporting
    ‚îÇ
    ‚îú‚îÄ‚îÄ requirements.txt   <- The requirements file for reproducing the analysis environment, e.g.
    ‚îÇ                         generated with `pip freeze > requirements.txt`
    ‚îÇ
    ‚îú‚îÄ‚îÄ setup.py           <- makes project pip installable (pip install -e .) so src can be imported
    ‚îú‚îÄ‚îÄ src                <- Source code for use in this project.
    ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ __init__.py    <- Makes src a Python module
    ‚îÇ   ‚îÇ
    ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ data           <- Scripts to download or generate data
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ make_dataset.py
    ‚îÇ   ‚îÇ
    ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ features       <- Scripts to turn raw data into features for modeling
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ build_features.py
    ‚îÇ   ‚îÇ
    ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ models         <- Scripts to train models and then use trained models to make
    ‚îÇ   ‚îÇ   ‚îÇ                 predictions
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ predict_model.py
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ train_model.py
    ‚îÇ   ‚îÇ
    ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ visualization  <- Scripts to create exploratory and results oriented visualizations
    ‚îÇ¬†¬†     ‚îî‚îÄ‚îÄ visualize.py
    ‚îÇ
    ‚îî‚îÄ‚îÄ tox.ini            <- tox file with settings for running tox; see tox.readthedocs.io


--------

<p><small>Project based on the <a target="_blank" href="https://drivendata.github.io/cookiecutter-data-science/">cookiecutter data science project template</a>. #cookiecutterdatascience</small></p>
