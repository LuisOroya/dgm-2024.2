# `S√≠ntese de Dados Financeiros`
==============================

# `Financial Data Synthesis`
==============================
## Link dos slides:
https://docs.google.com/presentation/d/1eOmgRpkQeXU1htM_7Gq66HRcn2CPZ7iB/edit?pli=1#slide=id.p1

Apresenta√ß√£o
==============================
<p align="justify">
O presente projeto foi originado no contexto das atividades da disciplina de p√≥s-gradua√ß√£o IA376N - Deep Learning aplicado a S√≠ntese de Sinais, oferecida no segundo semestre de 2024, na Unicamp, sob supervis√£o da Profa. Dra. Paula Dornhofer Paro Costa, do Departamento de Engenharia de Computa√ß√£o e Automa√ß√£o (DCA) da Faculdade de Engenharia El√©trica e de Computa√ß√£o (FEEC).
</p>

 |Nome  | RA | Curso|
 |--|--|--|
 |Jos√© Carlos Ferreira  | 170860  | Eng. El√©trica |
 |Byron Alejandro Acu√±a Acurio  | 209428  | Eng. El√©trica |

## Resumo (Abstract)
<p align="justify">
Neste trabalho foi testado a capacidade de dois modelos generativos baseados nas arquiteturas de Redes Advers√°rias Generativas (GANs) e Transformers na gera√ß√£o de pre√ßos de a√ß√µes.
 
O modelo baseado na arquitetura GAN foi desenvolvido utilizando Unidades Recorrentes Fechadas (GRU) como um gerador que insere o pre√ßo hist√≥rico das a√ß√µes e gera a previs√£o do pre√ßo futuro (no dia seguinte) das a√ß√µes e uma Rede Neural Convolucional (CNN) como um discriminador para discriminar entre o pre√ßo real das a√ß√µes e o pre√ßo das a√ß√µes gerado. Para estimar o pre√ßo da a√ß√£o foi usada 36 caracter√≠sticas como √≠ndice S&P 500, √≠ndice NASDAQ Composite, √≠ndice U.S. √çndice do d√≥lar, etc.


Comparamos os resultados do nosso modelo GAN e Transformer com modelos de aprendizado profundo baseados em LSTM e GRU. O modelo generativo apresenta um melhor desempenho em eventos extremos, em termos do erro quadr√°tico m√©dio RMSE.
</p>

## Introdu√ß√£o
Nosso projeto foca na gera√ß√£o de dados financeiros sint√©ticos realistas, especificamente geramos pre√ßos sint√©ticos da a√ß√£o da empresa Apple atrav√©s de duas abordagens: baseadas em GANS e Transformers.
Os dados sint√©ticos s√£o √∫teis em modelos em que a confian√ßa apenas em dados hist√≥ricos n√£o √© suficiente para construir um m√©todo robusto. Neste trabalho os experimentos foram realizados utilizando os pre√ßos no per√≠odo de 2010-2020, contemplando um evento extremo (Covid-19). Dessa forma, pudemos verificar a robustez de nossos modelos generativos frente a eventos extremos.
</p>

O projeto lida com s√©ries temporais da forma:

$$ X_{1:N}  = [{ x(1), x(2), ..., x(N) }]  $$

Em que cada elemento $x(i)$ representa o pre√ßo da a√ß√£o no instante $i$.

Atr√°ves da incorpora√ß√£o de features relevantes, tamb√©m representados por s√©ries temporais ($F_{1:N}$), buscamos gerar dados sint√©ticos que representam uma continua√ß√£o realista de $X_{1:N}$, isso √©, uma s√©rie temporal do tipo:

$$ X^{s}_{N+1:N+K}  = [{ x^{s}(N+1), x^{s}(N+2), ..., x^{s}(N+K) }]  $$

Tal que:

$$ X^{s}_{N+1:N+K}  \approx X\_{N+1:N+K}   $$



Por exemplo, se $X_{1:N}$ representa os pre√ßos da a√ß√£o da empresa Apple de 2010 at√© 2018, $X^{s}_{N+1:N+K}$ poderia representar valores plaus√≠veis de 2018 at√© 2020.

<!-- Essas representa√ß√µes realistas s√£o importantes, por exemplo, para modelos de otimiza√ß√£o de portf√≥lios, visto que podemos gerar diversos cen√°rios poss√≠veis e escolher a estrat√©gia que se sai melhor, considerando todas as possibilidades geradas. Dessa forma, o modelo de otimiza√ß√£o √© robusto e consegue bom desempenho nas mais diversas situa√ß√µes. -->
## Descri√ß√£o do Problema/Motiva√ß√£o
<p align="justify">
No setor financeiro, o acesso a dados do mundo real para an√°lise e treinamento de modelos √© limitado devido a quest√µes de privacidade e seguran√ßa. Assim os dados sint√©ticos podem ajudar a fornecer uma alternativa segura para disponibilizar esses dados para diversas organiza√ß√µes. O desenvolvimento de modelos com capacidade de prever o pre√ßo da a√ß√£o de forma precisa √© desafiador devido √† complexidade inerente desses dados. Em geral, os dados financeiros s√£o n√£o estacion√°rios e seguem distribui√ß√µes de probabilidade desconhecidas e dif√≠ceis de serem estimadas. Apesar dos avan√ßos nos algoritmos de deep learning, que conseguem capturar melhor essas complexidades, a escassez de dados financeiros dispon√≠veis tem sido um fator limitante na constru√ß√£o de m√©todos robustos. Especialmente em eventos extremos quando no hist√≥rico de dados nunca se teve um registro de um evento similar.
</p>

<p align="justify">
H√° um movimento crescente entre pesquisadores para otimizar modelos de machine learning atrav√©s da incorpora√ß√£o de dados financeiros sint√©ticos [4]. A gera√ß√£o de dados sint√©ticos permite melhorar o desempenho de m√©todos que, at√© ent√£o, apresentavam resultados insatisfat√≥rios ou eram invi√°veis na pr√°tica devido √† falta de dados, al√©m de possibilitar a simula√ß√£o de eventos raros ou extremos. 
</p>

<p align="justify">
Diversas metodologias t√™m sido estudadas. As arquiteturas da fam√≠lia Generative Adversarial Networks (GANs) t√™m mostrado bons resultados em tarefas de gera√ß√£o de imagens e, mais recentemente, est√£o sendo aplicadas na gera√ß√£o de dados financeiros sint√©ticos. Al√©m das GANs, as arquiteturas Transformers tamb√©m surgem como estruturas promissoras para a tarefa. 
</p>

<p align="justify">
A cria√ß√£o de dados financeiros que reproduzam o comportamento de dados reais √© essencial para v√°rias aplica√ß√µes, como o problema de otimiza√ß√£o de portf√≥lios. Considere um investidor com acesso a ùëõ classes de ativos. O problema de otimiza√ß√£o de portf√≥lio consiste em alocar esses ativos de modo a maximizar o retorno, escolhendo a quantidade apropriada para cada classe, enquanto mant√©m o risco do portf√≥lio dentro de um n√≠vel de toler√¢ncia predefinido. Pesquisas recentes em otimiza√ß√£o de portf√≥lios financeiros exploraram diversas abordagens para melhorar as estrat√©gias de aloca√ß√£o de ativos. A gera√ß√£o de dados sint√©ticos tem se destacado como uma boa solu√ß√£o para ampliar conjuntos de dados financeiros limitados, com estudos propondo modelos de regress√£o sint√©tica [1] e redes advers√°rias generativas condicionais modificadas [2].
</p>

<p align="justify">
Neste trabalho, nos focamos na gera√ß√£o de dados financeiros sint√©ticos realistas, especificamente sobre o pre√ßo da a√ß√£o da empressa Apple atrav√©s de duas abordagens: baseadas em GANS e Transformers. A gera√ß√£o de dados sint√©ticos √© particularmente √∫til para capturar cen√°rios de retorno que est√£o ausentes nos dados hist√≥ricos, mas s√£o estatisticamente plaus√≠veis.
</p>

## Objetivos

O projeto tem como **objetivo principal** :

-  Estudar e desenvolver dois modelos generativos (uma baseadas em GANs e outra em Transformers.) para gerar s√©ries temporais sint√©ticas realistas de ativos financeiros, retendo o m√°ximo de informa√ß√µes estat√≠sticas.

Para o projeto, escolhemos tr√™s ativos financeiros distintos:
- **Historico de dados dos pre√ßos da a√ß√£o da empressa Apple**: pre√ßo em dolares da a√ß√£o de Apple desde o 1¬∫ de julho de 2010 at√© 30 de junho de 2020 .

## Contribui√ß√µes
- Cria√ß√£o de um modelo generativo baseado em GAN  
- Cria√ß√£o de um modelo generativo baseado em Wasserstein GAN  
- Cria√ß√£o de um modelo generativo baseado em Transformers  
- Compara√ß√£o de desempenho com redes profundas baseadas em LSTM e GRU

Utilizamos como m√©trica de avalia√ß√£o o RMSE.

### Bases de Dados

|Base de Dados | Endere√ßo na Web | Resumo descritivo|
|----- | ----- | -----|
|API do Yahoo Finance| https://finance.yahoo.com | Permite o acesso a dados financeiros por meio de chamadas de API. Esses dados incluem pre√ßos de fechamento, pre√ßos m√°ximos, m√≠nimos, volume negociado. Al√©m disso, √© poss√≠vel coletar os dados considerando diferentes per√≠odos de amostragem: 2 minutos, 5 minutos, 15 minutos, 1 hora, 1 dia.|

## Metodologia e Workflow
**CASO 1: GANs**

A metodologia para a gera√ß√£o das s√©ries temporais sint√©ticas utilizando Redes Generativas Adversarias pode ser resumida no seguinte passo a passo:

1. **Coleta de Dados via API:**

<p align="justify">
O movimento do pre√ßo das a√ß√µes √© influenciado por muitos fatores. Ent√£o se precisa da maior quantidade de informa√ß√µes poss√≠veis. Por isso no caso das GANs o banco de dados criado alem da serie temporal dos pre√ßos de fechamento di√°rios (Close) da empresa Apple, temos os √≠ndices de mercado, os pre√ßos de commodities e os pre√ßos de a√ß√µes de grandes empresas como Amazon, Google e Microsoft. A continua√ß√£o se apresenta banco de dados criado a partir dos historicos de dados das series tempoais financieras utilizadas neste trabalho, a faixa temporal foi seleccionada intencionalmente para poder testar nossos modelos com um evento extremo (Covid19).
</p>

</p>
<div align="center">
    <img src="img_readme/Banco de Dados.png" alt="Banco de Dados" title="Banco de Dados" />
    <p><em>Figura 1: Historico de series temporais usadas para preveer o pre√ßo da a√ß√£o da Apple, usando redes generativas GANs.</em></p>
</div>


2. **Engenharia de Caracter√≠sticas:**

<p align="justify">
Depois de baixar os hist√≥ricos de dados das s√©ries temporais financeiras, calculamos alguns indicadores t√©cnicos e extra√≠mos algumas caracter√≠sticas de tend√™ncia. Al√©m disso, para avaliar as not√≠cias relevantes, foi inserido um score, e finalmente foram criadas features baseadas em transformadas de Fourier para extrair tend√™ncias de longo e curto prazo nas a√ß√µes da Apple.
</p>

<ul>
  <li>Indicadores t√©cnicos: M√©dia m√≥vel de 7 e 20 dias, m√©dia m√≥vel exponencial, momentum, bandas de Bollinger, MACD.</li>
  <li>An√°lise do sentimento das not√≠cias: Usamos o FinBert para analisar as not√≠cias em positivas, neutras ou negativas, usando o score fornecido que vai desde -1 at√© 1.</li>
  <li>Transformadas de Fourier: Foi obtida a magnitude e a fase das transformadas discretas de Fourier do pre√ßo das a√ß√µes, usando 3, 6 e 9 componentes.</li>
</ul>

</p>
<div align="center">
    <img src="img_readme/Tecnicos.png" alt="Features Baseadas em Indicadores T√©cnicos" title="Indicadores T√©cnicos" />
    <p><em>Figura 2: Features Baseadas em Indicadores T√©cnicos criadas como complemento para o banco de dados apresentado na Figura 1.</em></p>
</div>

<div align="center">
    <img src="img_readme/Fourier.png" alt="Features Baseadas em Transformadas de Fouerier" title="Transformadas de Fouerier" />
    <p><em>Figura 3: Features Baseadas em Transformadas de Fouerier criadas como complemento para o banco de dados apresentado na Figura 1.</em></p>
</div>

3. **Normaliza√ß√£o dos Dados:**

Ap√≥s a coleta dos dados e engenharia de features, armazenamos as s√©ries temporais (do pre√ßo e dos features) em um mesmo dataframe: 

$$D = [X_{1:N}, F_{1:N}]$$

Para facilitar o treinamento do modelo, os valores de cada s√©rie temporal foram normalizados utilizando a t√©cnica de normaliza√ß√£o min-max. A f√≥rmula adotada foi:

$$
x_{n}(i) = \frac{x(i) - \min(x)}{\max(x) - \min(x)}
$$

- $x_{n}(i)$: representa o valor normalizado de uma s√©rie temporal (pre√ßo ou algum feature) no instante $i$.
- $x(i)$: representa o valor original da s√©rie temporal (pre√ßo ou algum feature) no instante $i$.
- $\min(x)$: representa o menor valor na s√©rie temporal $x$.
- $\max(x)$: representa o maior valor na s√©rie temporal $x$.

Essa abordagem garante que os valores da s√©rie temporal sejam escalados para o intervalo $[0, 1]$, permitindo que o modelo processe os dados de forma eficiente e consistente.

4. **Constru√ß√£o da Rede Neural:**

<p align="justify">
A rede generativas adversarias (GAN) para predi√ß√£o de s√©ries temporais, usa como fun√ß√£o de perda a diverg√™ncia de Kullback-Leibler (KL) e a diverg√™ncia de Jensen-Shannon (JS), no processo de treinamento. Essas duas diverg√™ncia s√£o m√©tricas matem√°ticas usadas para medir a semelhan√ßa entre duas distribui√ß√µes de probabilidade. O modelo GAN usa no Discriminador a fun√ß√£o de perda baseada na diverg√™ncia de Jensen-Shannon (JS), que se apresenta a continua√ß√£o:

$$
-\frac{1}{m} \sum_{i=1}^m \log D\left(y^i\right)-\frac{1}{m} \sum_{i=1}^m\left(1-\log D\left(G\left(x^i\right)\right)\right)
$$


Neste projeto, o gerador foi treinado usando perda de entropia cruzada para minimizar a diferen√ßa entre duas distribui√ß√µes, o que equivale a minimizar a diverg√™ncia de Kullback-Leibler (KL), usando a fun√ß√£o de perda apresentada a continua√ß√£o

$$
-\frac{1}{m} \sum_{i=1}^m\left(\log D\left(G\left(x^i\right)\right)\right)
$$
 
 
 A rede generativa GAN √© composta por duas redes neurais: (i) Gerador e (ii) Discriminador. As fun√ß√µes de perda apresentadas anteriormente garantem um treinamento que combina um processo competitivo. Abaixo detalha-se a estrutura das redes neurais da GAN:
</p>
<div align="center">
    <img src="img_readme/GAN.png" alt="Estrutura GAN" title="Estrutura da rede generativa GAN" />
    <p><em>Figura 4: Estrutura da arquitetura GAN.</em></p>
</div>


<p align="justify">
O gerador foi construido usando uma sequ√™ncia de tr√™s camadas GRU (Gated Recurrent Unit) para processamento de dados sequenciais e tr√™s camadas densas para refinar os resultados e produzir o dado sint√©tico final. A sele√ß√£o das tr√™s camadas GRU foi por causa que neste trabalho foi usado os ultimos tr√™s d√≠as de dados hist√≥ricos para poder prever o d√≠a seguente. Na entrada se pode visualizar que temos as 36 features explicadas anteriormente nos passos 1 e 2. Por isso se pode visualzar que temos uma dimens√£o de entreda de Bs,3,36 onde Bs √© o tamanho do batch de treinamento. Neste estudo foi Bs = 128. Note-se que a GAN usada tem uma arquitetura condicional, onde a gera√ß√£o dos dados √© condicionada a alguns dados de entrada neste caso o contexto usado foi os valores passados reais do valor da a√ß√£o da Apple $yc$. 
</p>

<p align="justify">
Adicionalmente no caso das GANs, neste estudo foi explorada o tipo de GAN conhecidas na literatura como Wasserstein GAN com Gradient Penalty (WGAN-GP), que oferece vantagens significativas sobre as GANs padr√£o para gera√ß√£o de s√©ries temporais devido √† sua estabilidade de treinamento aprimorada e capacidade de mitigar desafios comuns, como colapso de modo. Por exemplo as GANs padr√£o, que dependem de perda de entropia cruzada bin√°ria, muitas vezes enfrentam gradientes inst√°veis, particularmente em cen√°rios onde o discriminador domina o gerador, levando a uma din√¢mica de aprendizagem abaixo do ideal. Este problema √© agravado em dados de s√©ries temporais, onde as depend√™ncias temporais e os padr√µes complexos aumentam a dificuldade de alcan√ßar um processo de forma√ß√£o equilibrado. O WGAN-GP aborda essas limita√ß√µes usando a perda de Wasserstein, que mede a diverg√™ncia entre distribui√ß√µes de dados reais e geradas por meio da Dist√¢ncia do Earth Mover, garantindo atualiza√ß√µes de gradiente suaves e significativas mesmo quando o discriminador funciona bem. Al√©m disso, a penalidade de gradiente imp√µe uma restri√ß√£o de Lipschitz ao discriminador sem recorrer ao corte de peso, melhorando a capacidade do discriminador de modelar as estruturas intrincadas inerentes aos dados de s√©ries temporais. Essas melhorias n√£o apenas promovem um treinamento est√°vel, mas tamb√©m reduzem o risco de colapso do modo, incentivando o gerador a produzir padr√µes de s√©ries temporais diversos e realistas. Ao alinhar mais estreitamente a distribui√ß√£o dos dados gerados com a distribui√ß√£o real, o WGAN-GP surge como uma escolha robusta para tarefas de modelagem de s√©ries temporais, permitindo a s√≠ntese de sequ√™ncias de alta qualidade com caracter√≠sticas temporais complexas.
</p>

<div align="center">
    <img src="img_readme/WGAN-GP.png" alt="Diferen√ßas da GAN com WGAN-GP" title="Diferen√ßas da GAN com WGAN-GP" />
    <p><em>Figura 5: Diferen√ßas da GAN com WGAN-GP.</em></p>
</div>

**CASO 2: TRANSFORMERS**

A metodologia para a gera√ß√£o das s√©ries temporais sint√©ticas utilizando arquitetura Transformers pode ser resumida no seguinte passo a passo:

1. **Coleta de Dados via API do Yahoo Finance:**
   
   Atrav√©s desse API, coletamos os pre√ßos com um per√≠odo de amostragem de 2 minutos, e armazenamos em um vetor que representa a s√©rie temporal: $X\_{1:N}$.
   
   O per√≠odo de amostragem de 2 minutos foi escolhido pois √© o menor que o API disponibiliza. Optamos por realizar uma an√°lise em alta frequ√™ncia, pois as varia√ß√µes nos pre√ßos n√£o s√£o t√£o abruptas comparadas √† de uma frequ√™ncia menor (e.g. valores di√°rios). Dessa forma, o modelo consegue gerar dados dentro de uma faixa razo√°vel de valores. A figura abaixo ilustra um exemplo.
   
<p align="justify">
A continua√ß√£o se apresenta a serie temporal dos pre√ßos da a√ß√£o da empressa Apple, a usada data usada dos dados foi desde 2010-07-01 at√© 2020-06-30, para fazer experimentos antes e depois do Covid-19 (evento extremo)
</p>

<div align="center">
    <img src="img_readme/Serie_temporal.png" alt="Pre√ßos_Vale" title="Pre√ßos Apple" />
    <p><em>Figura 6: Pre√ßos das a√ß√µes da Apple com um per√≠odo de amostragem de 2 minutos coletados do API do Yahoo Finance.</em></p>
</div>

2. **Extra√ß√£o de Features:**

   Para auxiliar na gera√ß√£o de dados sint√©ticos realistas, tamb√©m extraimos diversos features que ajudam a explicar o comportamento dos pre√ßos. Esses features tamb√©m s√£o s√©ries temporais, dados (cada um) por: $F\_{1:N}$. Eles possuem o mesmo n√∫mero de amostras da s√©rie temporal de pre√ßos.

Os features que se mostraram √∫teis na gera√ß√£o dos dados sint√©ticos foram:

   - Volume de a√ß√µes negociada;
   - √çndices t√©cnicos: Moving Average Convergence Divergence (MACD), Stochastic Oscillator (SO), Commodity Channel Index (CCI), Money Flow Index (MFI);
  
Os √≠ndices t√©cnicos s√£o algumas m√©tricas que podem ser calculadas a partir do pre√ßo de fechamento, pre√ßo m√°ximo e m√≠nimo, al√©m do volume de a√ß√µes negociadas. Esses √≠ndices t√©cnicos buscam capturar as tend√™ncias de movimenta√ß√£o dos pre√ßos. A figura abaixo ilustra um exemplo de um feature utilizado:

<div align="center">
    <img src="img_readme/vol.png" alt="Volume_Vale" title="Volume de A√ß√µes da Apple" />
    <p><em>Figura 7: Volume de a√ß√µes da Apple negociadas com um per√≠odo de amostragem de 2 minutos coletados do API do Yahoo Finance.</em></p>
</div>

3. **Normaliza√ß√£o dos Dados:**

   Ap√≥s a coleta dos dados e extra√ß√£o dos features, armazenamos as s√©ries temporais (do pre√ßo e dos features) em um mesmo dataframe: $D=[X\_{1:N}, F\_{1:N} ]$.
   
   Ap√≥s isso, normalizamos os valores de cada s√©rie temporal para facilitar o treinamento, utilizando as suas respectivas m√©dias e desvios padr√µes. A normaliza√ß√£o adotada foi:

$$ x_{n}(i) = \frac{x(i) - \text{m√©dia[x]}}{\text{desvio padr√£o[x]}}$$

- $x_{n}(i)$: representa o valor normalizado de uma s√©rie temporal (pre√ßo ou algum feature) no instante $i$.
-  $x(i)$: representa o valor antes da normaliza√ß√£o (pre√ßo ou algum feature) no instante $i$.
- m√©dia[x], desvio padr√£o [x] : representam a m√©dia e o desvio padr√£o associado √† s√©rie temporal dos elementos de x(i)  

   
4. **Constru√ß√£o da Rede Neural:**

   A rede neural √© um modelo baseado na arquitetura Transformer sendo utilizado para predi√ß√£o de s√©ries temporais. Ele processa sequ√™ncias de dados para predizer o valor futuro com base nas observa√ß√µes passadas. A figura abaixo ilustra o modelo, de maneira simplificada, atr√°ves de blocos:
   <div align="center">
    <img src="Arquitetura_Blocos.png" alt="Arquitetura" title="Arquitetura" />
    <p><em>Figura 8: Estrutura simplificada do modelo baseado na arquitetura Transformer. </em></p>
</div>

- **Input:**
   
   A entrada √© um dataframe D contendo a s√©rie temporal do pre√ßo $X_{1:N}$ e dos features $F\_{1:N}$.
   
- **Sequenciador das S√©ries Temporais:**
   
   As s√©ries temporais s√£o repartidas em sequ√™ncias de tamanho fixo (tam_seq) para o processamento nos blocos Transformers. Al√©m disso, associamos a cada sequ√™ncia um target, que representa o valor que desejamos prever (r√≥tulo). Para o treinamento, a rede recebe um conjunto de sequ√™ncias e os r√≥tulos correspondentes.
   
- **Layer de Input:**
   
   A entrada da rede √© um vetor multidimensional que cont√©m todas as sequ√™ncias de tamanho tam_seq para todos os features.
   
- **Embedding Layer:**

   A embedding layer √© uma camada densa que transforma os dados em um espa√ßo dimensional maior. √â √∫til para que o modelo aprenda rela√ß√µes mais complexas nos dados.

- **Positional Encoding:**

   Adiciona informa√ß√µes sobre a posi√ß√£o de cada elemento da sequ√™ncia, visto que o Transformer n√£o conhece a ordem temporal dos dados. Isso permite que o modelo saiba a ordem temporal dos dados.

- **Blocos Transformers:**

   Sequ√™ncias de blocos da arquitetura Transformer, cada bloco possui os seguintes elementos:

   - Layer MultiHead Attention: permite que o modelo se concentre em diferentes partes da sequ√™ncia para realizar a predi√ß√£o
   - Conex√£o Residual e Normaliza√ß√£o: adiciona a entrada do bloco √† sa√≠da do layer MultiHead Attention e normaliza os valores. Isso ajuda na estabiliza√ß√£o de treinamento.
   - Rede Feed-Forward: duas camadas densas com fun√ß√£o de ativa√ß√£o ReLU na primeira.
     
- **Global Average Pooling:**
    
   Reduz a sa√≠da dos blocos transformers para um vetor de tamanho fixo atrav√©s do c√°lculo da m√©dia dos valores.

- **Output Layer**:

    Camada densa que gera o valor predito. No nosso modelo, predizemos apenas um √∫nico valor por vez.

Os detalhes espec√≠ficos da constitui√ß√£o de cada bloco est√£o descritos neste link: [Detalhes_Arquitetura](docs/Arquitetura.md)

5. **Treinamento:**

Ap√≥s a constru√ß√£o do modelo, partimos para a etapa de treinamento. Nesta etapa, o nossos dados de entrada $D = [X_{1:N}, F_{1:N}]$ s√£o separados em conjunto de treinamento, valida√ß√£o e teste:

- Conjunto de treinamento: Os 70% primeiros elementos do dataset de entrada
- Conjunto de valida√ß√£o:      20% dos elementos do dataset
- Conjunto de teste:       Os 10% √∫ltimos elementos do dataset de entrada

Por exemplo, se o dataset de entrada s√£o s√©ries temporais com 1000 elementos, ent√£o os 700 primeiros elementos s√£o utilizados para treinamento, os 200 elementos seguintes para valida√ß√£o, e os √∫ltimos 100 para teste. Foi importante garantir que os dados estejam ordenados, pois apresentam depend√™ncias temporais.

Conforme explicado no bloco de sequenciamento das s√©ries temporais, os dados s√£o transformados em sequ√™ncias de tamanho fixo. No nosso caso, observamos que sequ√™ncias com 24 instantes de tempo consecutivos apresentaram os melhores resultados. Logo, o modelo recebe como entrada sequ√™ncias com 24 elementos consecutivos e o r√≥tulo associado, que no caso, seria o 25¬∫ elemento.

Ou seja, dado os √∫ltimos 24 pre√ßos (e features), o modelo tentar√° prever o 25¬∫ pre√ßo, e a verifica√ß√£o da qualidade da solu√ß√£o ser√° dado pela compara√ß√£o com o valor do r√≥tulo que √© o valor real do 25¬∫ pre√ßo.

Para o treinamento, foi utilizado os seguintes hiperpar√¢metros:
- Otimizador: Adaptative Moment Estimator (Adam);
- Fun√ß√£o de perda: Mean Absolute Error;
-  Batch size: 128;
-  N√∫mero de √©pocas: 200 (com early stopping);

  A escolha dos melhores par√¢metros foi baseado na perda observada para o conjunto de valida√ß√£o.

  6. **Infer√™ncia:**

Ap√≥s o treinamento, utilizamos o modelo para prever os pontos do conjunto de teste e comparamos com os respectivos r√≥tulos associados.

A figura abaixo ilustra o workflow:

 <div align="center">
    <img src="Workflow.png" alt="Workflow" title="Workflow" />
    <p><em>Figura 9: Workflow contemplando o processo de treinamento e infer√™ncia. </em></p>
</div>

## Experimentos, Resultados e Discuss√£o dos Resultados




### Artigos de Refer√™ncia
Os principais artigos que o grupo j√° identificou como base para estudo e planejamento do projeto s√£o:

- **Pagnocelli. (2022)**: "A Synthetic Data-Plus-Features Driven Approach for Portfolio Optimization" [5].
  
- **Pe√±a et al. (2024)**: "A modified CTGAN-plus-features-based method for optimal asset allocation" [2].

-  **F.Eckerli, J.Osterrieder.** "Generative Adversarial Networks in finance: an overview" [3]. 

### Ferramentas
Existem diversas bibliotecas Python dispon√≠veis para gera√ß√£o de dados sint√©ticos, cada uma com suas capacidades e recursos distintos. Neste trabalho exploraremos as seguintes bibliotecas CTGAN  e Synthetic Data Vault (SDV).

- **CTGAN** √© uma cole√ß√£o de geradores de dados sint√©ticos baseados em Deep Learning para dados de tabela √∫nica, que s√£o capazes de aprender com dados reais e gerar dados sint√©ticos com alta fidelidade. 

- **SDV (Synthetic Data Vault)** O pacote √© focado na gera√ß√£o e avalia√ß√£o de dados sint√©ticos tabulares, multitabelas e s√©ries temporais. Aproveitando uma combina√ß√£o de modelos de aprendizado de m√°quina, o SDV fornece recursos e s√≠ntese de dados, ao mesmo tempo em que garante que os conjuntos de dados gerados se assemelhem aos dados originais em estrutura e propriedades estat√≠sticas. 

- **Python** com bibliotecas como `PyTorch` e `scikit-learn` para implementar os modelos generativos e realizar a s√≠ntese de dados.
   
- **Colab** para colabora√ß√£o e execu√ß√£o de experimentos em ambientes com suporte a GPU.
  
- **Pandas** e **NumPy** para manipula√ß√£o de dados tabulares.

### Proposta de Avalia√ß√£o
Para a avalia√ß√£o da qualidade dos nossos geradores de dados sint√©ticos, al√©m dos fatos estilizados, vamos considerar v√°rias outras m√©tricas utilizando amostras reais e sint√©ticas. As m√©tricas de avalia√ß√£o que pretendemos utilizar s√£o:

Compara√ß√£o entre as distribui√ß√µes sint√©ticos e hist√≥ricos usando m√©tricas que capturam os aspectos distribucionais dos dados sint√©ticos com rela√ß√£o √†s amostras reais. Neste caso vamos usar o teste Kolmogorov-Smirnov (KS), teste Qui-quadrado (CS) que medem a similaridade para vari√°veis ‚Äã‚Äãcont√≠nuas e categ√≥ricas (colunas) respectivamente. A medidas de diverg√™ncia distribucional como dist√¢ncia de Jensen-Shannon, Discrep√¢ncia M√©dia M√°xima (MMD) e dist√¢ncia de Wasserstein. Gr√°ficos de similaridade T-SNE bidemnsional para verificar visualmente a similaridade distribucional entre dados reais e sint√©ticos. 

## Conclus√£o
Por fim, a principal dificuldade do projeto ser√° gerar os dados financeiros sint√©ticos realistas. Abordaremos diversas estrat√©gias que v√£o desde o pr√©-processamento dos dados, ajustes nos hiperpar√¢metros das GANs e o emprego de m√©tricas eficientes.
 
## Refer√™ncias Bibliogr√°ficas
[1] Li, Gaorong, Lei Huang, Jin Yang, and Wenyang Zhang.  
"A synthetic regression model for large portfolio allocation."  
*Journal of Business & Economic Statistics* 40, no. 4 (2022): 1665-1677.

[2] Pe√±a, Jos√©-Manuel, Fernando Su√°rez, Omar Larr√©, Domingo Ram√≠rez, and Arturo Cifuentes. 
"A modified CTGAN-plus-features-based method for optimal asset allocation".
" Quantitative Finance 24, no. 3-4 (2024): 465-479".

[3] https://mba.tuck.dartmouth.edu/pages/faculty/ken.french/data_library.html

[4] F.Eckerli, J.Osterrieder.
" Generative Adversarial Networks in finance: an overview."

[5]- Bernardo K. Pagnoncelli, Arturo Cifuentes, Domingo Ram√≠rez and Hamed Rahimian.
 "A Synthetic Data-Plus-Features Driven Approach for Portfolio Optimization".
 Computational Economics, 2023, Volume 62, Number 1, Page 187.


Project Organization
------------

    ‚îú‚îÄ‚îÄ LICENSE
    ‚îú‚îÄ‚îÄ Makefile           <- Makefile with commands like `make data` or `make train`
    ‚îú‚îÄ‚îÄ README.md          <- The top-level README for developers using this project.
    ‚îú‚îÄ‚îÄ data
    ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ external       <- Data from third party sources.
    ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ interim        <- Intermediate data that has been transformed.
    ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ processed      <- The final, canonical data sets for modeling.
    ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ raw            <- The original, immutable data dump.
    ‚îÇ
    ‚îú‚îÄ‚îÄ docs               <- A default Sphinx project; see sphinx-doc.org for details
    ‚îÇ
    ‚îú‚îÄ‚îÄ models             <- Trained and serialized models, model predictions, or model summaries
    ‚îÇ
    ‚îú‚îÄ‚îÄ notebooks          <- Jupyter notebooks. Naming convention is a number (for ordering),
    ‚îÇ                         the creator's initials, and a short `-` delimited description, e.g.
    ‚îÇ                         `1.0-jqp-initial-data-exploration`.
    ‚îÇ
    ‚îú‚îÄ‚îÄ references         <- Data dictionaries, manuals, and all other explanatory materials.
    ‚îÇ
    ‚îú‚îÄ‚îÄ reports            <- Generated analysis as HTML, PDF, LaTeX, etc.
    ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ figures        <- Generated graphics and figures to be used in reporting
    ‚îÇ
    ‚îú‚îÄ‚îÄ requirements.txt   <- The requirements file for reproducing the analysis environment, e.g.
    ‚îÇ                         generated with `pip freeze > requirements.txt`
    ‚îÇ
    ‚îú‚îÄ‚îÄ setup.py           <- makes project pip installable (pip install -e .) so src can be imported
    ‚îú‚îÄ‚îÄ src                <- Source code for use in this project.
    ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ __init__.py    <- Makes src a Python module
    ‚îÇ   ‚îÇ
    ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ data           <- Scripts to download or generate data
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ make_dataset.py
    ‚îÇ   ‚îÇ
    ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ features       <- Scripts to turn raw data into features for modeling
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ build_features.py
    ‚îÇ   ‚îÇ
    ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ models         <- Scripts to train models and then use trained models to make
    ‚îÇ   ‚îÇ   ‚îÇ                 predictions
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ predict_model.py
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ train_model.py
    ‚îÇ   ‚îÇ
    ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ visualization  <- Scripts to create exploratory and results oriented visualizations
    ‚îÇ¬†¬†     ‚îî‚îÄ‚îÄ visualize.py
    ‚îÇ
    ‚îî‚îÄ‚îÄ tox.ini            <- tox file with settings for running tox; see tox.readthedocs.io


--------

<p><small>Project based on the <a target="_blank" href="https://drivendata.github.io/cookiecutter-data-science/">cookiecutter data science project template</a>. #cookiecutterdatascience</small></p>
