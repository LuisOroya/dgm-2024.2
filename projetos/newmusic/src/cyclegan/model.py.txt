import numpy as np
import torch
import torch.nn as nn
from torch.nn import functional as F
import copy
import logging
import logger


logger = logging.getLogger()

def kernel_initializer(w: torch.Tensor, mean: float = 0.0, std: float = 0.02):
    """Applies normal initialization to the given tensor."""
    return nn.init.normal_(w, mean, std)


def padding(x: torch.Tensor, p: int = 3):
    """Adds reflection padding to the input tensor."""
    return F.pad(x, (p, p, p, p), mode='reflect')


def cycle_loss(real_a: torch.Tensor, cycle_a: torch.Tensor,
               real_b: torch.Tensor, cycle_b: torch.Tensor) -> torch.Tensor:
    """Calculates cycle-consistency loss."""
    return F.l1_loss(cycle_a, real_a, reduction='mean') + F.l1_loss(cycle_b, real_b, reduction='mean')


class InstanceNorm2d(nn.InstanceNorm2d):
    def __init__(self, num_features: int, affine: bool = False):
        """Instance normalization layer with optional affine parameters."""
        super().__init__(num_features, affine=affine)

    def reset_parameters(self) -> None:
        """Resets parameters of the instance normalization layer."""
        self.reset_running_stats()
        if self.affine:
            self.weight = kernel_initializer(self.weight, mean=1.0, std=0.02)
            nn.init.zeros_(self.bias)


class ResNetBlock(nn.Module):
    def __init__(self, dim: int, kernel_size: int = 3, stride: int = 1):
        super().__init__()
        padding_size = (kernel_size - 1) // 2
        self.layer1 = nn.Sequential(
            nn.Conv2d(dim, dim, kernel_size, stride, bias=False, padding=padding_size),
            InstanceNorm2d(dim, affine=True),
            nn.ReLU(inplace=True)
        )
        kernel_initializer(self.layer1[0].weight)

        self.layer2 = nn.Sequential(
            nn.Conv2d(dim, dim, kernel_size, stride, bias=False, padding=padding_size),
            InstanceNorm2d(dim, affine=True)
        )
        kernel_initializer(self.layer2[0].weight)

        self.relu = nn.ReLU(inplace=True)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        y = self.layer1(x)
        y = self.layer2(y)
        return self.relu(x + y)


class Discriminator(nn.Module):
    def __init__(self, dim: int = 64):
        super().__init__()
        self.discriminator = nn.Sequential(
            nn.Conv2d(1, dim, kernel_size=7, stride=2, padding=3, bias=False),
            nn.LeakyReLU(negative_slope=0.2, inplace=True),
            nn.Conv2d(dim, 4 * dim, kernel_size=7, stride=2, padding=3, bias=False),
            InstanceNorm2d(4 * dim, affine=True),
            nn.LeakyReLU(negative_slope=0.2, inplace=True),
            nn.Conv2d(4 * dim, 1, kernel_size=7, stride=1, padding=3, bias=False)
        )

        for i in [0, 2, 5]:
            kernel_initializer(self.discriminator[i].weight)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        return self.discriminator(x)


class Generator(nn.Module):
    def __init__(self, dim: int = 64):
        super().__init__()
        self.encoder = nn.Sequential(
            nn.Conv2d(1, dim, kernel_size=7, stride=1, bias=False, padding=3),
            InstanceNorm2d(dim, affine=True),
            nn.ReLU(inplace=True),
            nn.Conv2d(dim, 2 * dim, kernel_size=3, stride=2, padding=1, bias=False),
            InstanceNorm2d(2 * dim, affine=True),
            nn.ReLU(inplace=True),
            nn.Conv2d(2 * dim, 4 * dim, kernel_size=3, stride=2, padding=1, bias=False),
            InstanceNorm2d(4 * dim, affine=True),
            nn.ReLU(inplace=True)
        )
        self.resnet_blocks = nn.Sequential(*[ResNetBlock(4 * dim) for _ in range(10)])

        self.decoder = nn.Sequential(
            nn.ConvTranspose2d(4 * dim, 2 * dim, kernel_size=3, stride=2, padding=1, output_padding=1, bias=False),
            InstanceNorm2d(2 * dim, affine=True),
            nn.ReLU(inplace=True),
            nn.ConvTranspose2d(2 * dim, dim, kernel_size=3, stride=2, padding=1, output_padding=1, bias=False),
            InstanceNorm2d(dim, affine=True),
            nn.ReLU(inplace=True)
        )
        self.output = nn.Conv2d(dim, 1, kernel_size=7, stride=1, bias=False, padding=3)
        kernel_initializer(self.output.weight)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        x = self.encoder(x)
        x = self.resnet_blocks(x)
        x = self.decoder(x)
        return torch.sigmoid(self.output(x))


class Classifier(nn.Module):
    def __init__(self, dim: int = 64):
        super().__init__()
        self.cla = nn.Sequential(
            nn.Conv2d(1, dim, kernel_size=(1, 12), stride=(1, 12), bias=False),
            nn.LeakyReLU(negative_slope=0.2, inplace=True),
            nn.Conv2d(dim, 2 * dim, kernel_size=(4, 1), stride=(4, 1), bias=False),
            InstanceNorm2d(2 * dim, affine=True),
            nn.LeakyReLU(negative_slope=0.2, inplace=True),
            nn.Conv2d(2 * dim, 4 * dim, kernel_size=(2, 1), stride=(2, 1), bias=False),
            InstanceNorm2d(4 * dim, affine=True),
            nn.LeakyReLU(negative_slope=0.2, inplace=True),
            nn.Conv2d(4 * dim, 8 * dim, kernel_size=(8, 1), stride=(8, 1), bias=False),
            InstanceNorm2d(8 * dim, affine=True),
            nn.LeakyReLU(negative_slope=0.2, inplace=True),
            nn.Conv2d(8 * dim, 2, kernel_size=(1, 7), stride=(1, 7), bias=False)
        )
        self.softmax = nn.Softmax(dim=1)

        for i in [0, 2, 5, 8, 11]:
            kernel_initializer(self.cla[i].weight)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        x = self.cla(x)
        return self.softmax(x).squeeze(-1).squeeze(-1)


class Sampler:
    def __init__(self, max_length: int = 50):
        self.maxsize = max_length
        self.num = 0
        self.images = []

    def __call__(self, image):
        current_batch_size = image[0].size(0)
        if self.maxsize <= 0:
            return image
        if self.num < self.maxsize:
            self.images.append([img.detach() for img in image])
            self.num += 1
            return image
        if np.random.rand() > 0.5:
            idx = int(np.random.rand() * self.maxsize)
            tmp1 = self.images[idx][0].clone()
            tmp2 = self.images[idx][1].clone()

            # Ajuste o tamanho dos tensores para coincidir com o batch atual
            tmp1 = tmp1[:current_batch_size]
            tmp2 = tmp2[:current_batch_size]

            return [tmp1, tmp2]
        else:
            return image
        

class CycleGAN(nn.Module):
    #def __init__(self, sigma: float = 0.01, sample_size: int = 50, lamb: float = 10.0, mode: str = 'train'):
    def __init__(self, sigma: float = 1, sample_size: int = 50, lamb: float = 10.0, mode: str = 'train'):    
        super().__init__()
        assert mode in ['train', 'A2B', 'B2A'], "Mode must be one of ['train', 'A2B', 'B2A']"
        self.G_A2B = Generator(64)
        self.G_B2A = Generator(64)
        self.D_A = Discriminator(64)
        self.D_B = Discriminator(64)
        self.D_A_all = Discriminator(64)
        self.D_B_all = Discriminator(64)
        self.l2loss = nn.MSELoss(reduction='mean')
        self.sigma = sigma
        self.mode = mode
        self.sampler = Sampler(sample_size)
        self.lamb = lamb

    def forward(self, real_A, real_B, x_m):
        fake_B = self.G_A2B(real_A)
        cycle_A = self.G_B2A(fake_B)
        fake_A = self.G_B2A(real_B)
        cycle_B = self.G_A2B(fake_A)

        if self.mode == 'train':
            sample_fake_A, sample_fake_B = self.sampler([fake_A, fake_B])
            gauss_noise = torch.abs(kernel_initializer(torch.ones_like(real_A), mean=0, std=self.sigma))

            if sample_fake_A.size() != gauss_noise.size():
                logger.info(f"Size sample_fake_A: {sample_fake_A.size()}. Size sample_fake_B: {sample_fake_B.size()}. Size gauss_noise: {gauss_noise.size()}")
                sample_fake_A = F.interpolate(sample_fake_A, size=gauss_noise.size()[2:])
                sample_fake_B = F.interpolate(sample_fake_B, size=gauss_noise.size()[2:])
                logger.info(f"Tamanhos ajustados! Size sample_fake_A: {sample_fake_A.size()}. Size sample_fake_B: {sample_fake_B.size()}. Size gauss_noise: {gauss_noise.size()}")

            DA_real = self.D_A(real_A + gauss_noise)
            DB_real = self.D_B(real_B + gauss_noise)
            DA_fake = self.D_A(fake_A + gauss_noise)
            DB_fake = self.D_B(fake_B + gauss_noise)
            DA_fake_sample = self.D_A(sample_fake_A + gauss_noise)
            DB_fake_sample = self.D_B(sample_fake_B + gauss_noise)

            DA_real_all = self.D_A_all(x_m + gauss_noise)
            DB_real_all = self.D_B_all(x_m + gauss_noise)
            DA_fake_all = self.D_A_all(sample_fake_A + gauss_noise)
            DB_fake_all = self.D_B_all(sample_fake_B + gauss_noise)

            c_loss = self.lamb * cycle_loss(real_A, cycle_A, real_B, cycle_B)

            g_A2B_loss = self.l2loss(DB_fake, torch.ones_like(DB_fake)) + c_loss
            g_B2A_loss = self.l2loss(DA_fake, torch.ones_like(DA_fake)) + c_loss

            d_A_loss_real = self.l2loss(DA_real, torch.ones_like(DA_real))
            d_A_loss_fake = self.l2loss(DA_fake_sample, torch.zeros_like(DA_fake_sample))
            d_A_loss = (d_A_loss_real + d_A_loss_fake) / 2
            d_B_loss_real = self.l2loss(DB_real, torch.ones_like(DB_real))
            d_B_loss_fake = self.l2loss(DB_fake_sample, torch.zeros_like(DB_fake_sample))
            d_B_loss = (d_B_loss_real + d_B_loss_fake) / 2

            d_A_all_loss_real = self.l2loss(DA_real_all, torch.ones_like(DA_real_all))
            d_A_all_loss_fake = self.l2loss(DA_fake_all, torch.zeros_like(DA_fake_all))
            d_A_all_loss = (d_A_all_loss_real + d_A_all_loss_fake) / 2
            d_B_all_loss_real = self.l2loss(DB_real_all, torch.ones_like(DB_real_all))
            d_B_all_loss_fake = self.l2loss(DB_fake_all, torch.zeros_like(DB_fake_all))
            d_B_all_loss = (d_B_all_loss_real + d_B_all_loss_fake) / 2

            return (c_loss, g_A2B_loss, g_B2A_loss, d_A_loss, d_B_loss, d_A_all_loss, d_B_all_loss)

        elif self.mode == 'A2B':
            return fake_B, cycle_A
        elif self.mode == 'B2A':
            return fake_A, cycle_B
