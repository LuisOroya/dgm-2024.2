# `Gera√ß√£o e Avalia√ß√£o de Dados Sint√©ticos para PRPD`
# `Generation and Evaluation of Synthetic Data for PRPD`

## Apresenta√ß√£o

O presente projeto foi originado no contexto das atividades da disciplina de p√≥s-gradua√ß√£o *IA376N - IA generativa: de modelos a aplica√ß√µes multimodais*, 
oferecida no segundo semestre de 2024, na Unicamp, sob supervis√£o da Profa. Dra. Paula Dornhofer Paro Costa, do Departamento de Engenharia de Computa√ß√£o e Automa√ß√£o (DCA) da Faculdade de Engenharia El√©trica e de Computa√ß√£o (FEEC).

> |Nome  | RA | Especializa√ß√£o|
> |--|--|--|
> | Jos√© Alfredo Zapana Garc√≠a | 272291 | Aluno de mestrado em Eng. El√©trica |
> | S√≠lvia Claudino Martins Gomes | 271629  | Aluna Especial |

## Resumo (Abstract)

A fase-resolvida de descargas parciais (PRPD) √© uma representa√ß√£o gr√°fica da atividade de descargas parciais (PD) ao longo dos 360¬∫ de um ciclo de corrente alternada (CA). Essa t√©cnica √© amplamente utilizada no diagn√≥stico de falhas em equipamentos de alta pot√™ncia (HV), como motores el√©tricos, transformadores e sistemas de distribui√ß√£o de energia. A an√°lise de PRPD n√£o s√≥ permite a detec√ß√£o precoce de falhas potenciais, mas tamb√©m fornece informa√ß√µes valiosas sobre a natureza e a gravidade das descargas parciais. Apesar de haver fontes que relacionam tipos de falhas a suas representa√ß√µes gr√°ficas, encontrar bases de dados com alto volume de dados e de qualidade torna-se dif√≠cil, devido √† quest√µes de privacidade, accesibilidade a equipamentos e por ser um tema de pesquisa altamente especifico. No entanto, grandes quantidades de dados s√£o necess√°rias para treinar eficazmente modelos de deep learning. Dada a escassez de bases de dados apropriadas, a gera√ß√£o sint√©tica de imagens surge como uma solu√ß√£o promissora. Este projeto busca desenvolver e avaliar modelos generativos de imagens de PRPD, com o intuito de aumentar a quantidade e diversidade de dados dispon√≠veis.

## Descri√ß√£o do Problema/Motiva√ß√£o

Phase-Resolved Partial Discharge (PRPD) √© uma representa√ß√£o gr√°fica da atividade de descargas parciais (PD) ao longo dos 360¬∫ de um ciclo de corrente alternada (CA), amplamente utilizada no diagn√≥stico de falhas em equipamentos de alta pot√™ncia (HV), por ex. motores el√©tricos. Normalmente, essas descargas parciais t√™m um efeito negativo, reduzindo o ciclo de vida √∫til e o desempenho dos equipamentos. Elas afetam os isolamentos, comprometendo sua integridade e, em alguns casos, podem resultar em curtos-circuitos nos distribuidores de energia el√©trica, levando a interrup√ß√µes no servi√ßo e custos elevados de manuten√ß√£o. A an√°lise de PRPD n√£o s√≥ permite a detec√ß√£o precoce de falhas potenciais, mas tamb√©m fornece informa√ß√µes valiosas sobre a natureza e a gravidade das descargas parciais. Embora existam fontes que apresentam tipos de falhas e suas representa√ß√µes gr√°ficas, √© dif√≠cil encontrar bases de dados de qualidade, devido √† natureza especializada dos dados, conflitos por seguran√ßa e privacidade, acesso aos equipamentos, etc. Al√©m disso, grandes conjuntos de dados s√£o necess√°rios para treinar modelos de deep learning de forma eficaz. Dada a escassez de bases de dados adequadas, a gera√ß√£o sint√©tica de imagens se apresenta como uma solu√ß√£o vi√°vel para esse problema. 
[Link para o slide](https://docs.google.com/presentation/d/10h3jkcC1OpaIp1o4AaWeLi4mIFBhb0lt0KU67_mCWE8/edit?usp=sharing)

## Objetivo

### Objetivo Principal
O objetivo principal deste projeto √© o desenvolvimento e avalia√ß√£o de modelos generativos de imagens de PRPD. Dessa forma, ser√° poss√≠vel aumentar a variabilidade e o n√∫mero de dados dispon√≠veis. 

#### Objetivos Secund√°rios
- Implementar e adaptar modelos generativos artificiais para sintetizar padr√µes de PRPD.
- Realizar uma busca para otimizar os hiperpar√¢metros dos modelos.
- Avaliar os modelos por meio de m√©tricas quantitativas e qualitativas.
- Determinar qual modelo est√° melhor condicionado para a tarefa de gerar PRPDs sint√©ticos.

## Metodologia

### Informa√ß√µes Computacionais  

Para o desenvolvimento desde projeto, foram utilizados tr√™s computadores distintos:

1. Computador 1
- Processador: AMD Ryzen 9 4900HS 3GHz
- RAM: 16 GB
- GPU: Nvidia RTX 2060 Max-Q 6GB
2. Computador 2
- n1-standard-1 (1 vCPUs)
- RAM: 3,75 GB de RAM
- GPU NVIDIA T4 x 1
3. Computador 3
- Processador: Intel(R) Core(TM) i7-8565U CPU @ 1.80GHz (8 CPUs), ~2.0GHz
- RAM: 16, 384 MB 

### Bases de Dados e Evolu√ß√£o

Para o desenvolvimento deste projeto, ser√£o geradas imagens sint√©ticas com base em um conjunto de dados existente. O conjunto selecionado √© proveniente do artigo "Dataset of phase-resolved images of internal, corona, and surface partial discharges in electrical generators", que cont√©m imagens relacionadas a tr√™s tipos principais de falhas em motores el√©tricos: Corona, Internal e Surface, al√©m de algumas imagens que representam ru√≠dos. A seguir ser√° apresentada a tabela com as principais informa√ß√µes da base de dados.

| Base de Dados | Endere√ßo na Web | Resumo                                                             |
|------------|-----------------------|---------------------------------------------------------------------|
| Images of Resolved Phase Patterns of Partial Discharges in Electric Generators | https://data.mendeley.com/datasets/xz4xhrc4yr/8 | Este conjunto de dados cont√©m imagens de padr√µes de fase resolvidos de descargas parciais tipo corona, superficiais e internos obtidos de geradores el√©tricos localizados na Colombia e um simulador de descargas parciais de Omycron Energy.|

A escolha desse dataset se justifica por sua qualidade e relev√¢ncia no contexto de estudo de descargas parciais, oferecendo uma base s√≥lida para a cria√ß√£o de dados sint√©ticos. A tabela a seguir resume a quantidade de imagens por tipo de falha:
| Tipo de DP | Quantidade de Imagens | Exemplo                                                             |
|------------|-----------------------|---------------------------------------------------------------------|
| Corona     | 308                   | ![Corona](./data/raw/example_corona.png)                              |
| Internal   | 321                   | ![Internal](./data/raw/example_internal.png)                          |
| Surface    | 316                   | ![Surface](./data/raw/example_surface.png)                            |
| Noise      | 5                     | ![Noise](./data/raw/example_noise.png)                                |
| **Total**  | 950                   |                                                                     |

A imagem dos dataset possui tamanho de 640 x480 pixels. As anota√ß√µes s√£o pelo defeito do motor. A seguir √© apresentada a quantidade percentual de cada tipo de defeito nos dados. 

![defect](./reports/figures/dataset_distribution_by_class.png)

Foi realizada a divis√£o por tipo de motor anotado. Dessa forma, a representa√ß√£o do mesmo motor n√£o estar√° no conjunto de teste e treino, evitando *data leakage*. Posteriormente h√° o gr√°fico da quantidade de cada motor por defeito analisado. 

![motor_and_defect](./reports/figures/dataset_distribution_by_motor_and_defect.png)

Adicionalmente, se realizou uma an√°lise de variabilidade intra-classe e inter-classe por meio da m√©trica MS-SSIM para entender a complexidade do dataset

|            | Corona                | Internal         | Surface       |
|------------|-----------------------|------------------|----------------
| Corona     | 0.584                 | 0.495            | 0.393               |
| Internal   | 0.495                 | 0.444            | 0.404|
| Surface    | 0.393                 | 0.404            | 0.390|


### Separa√ß√£o de dados
O dataset ser√° separado em tr√™s grupos: treino, valida√ß√£o e teste. O primeiro conjunto ser√° utilizado para treinar as arquiteturas escolhidas, o segundo para otimizar os hiperpar√¢metros, e o terceiro para avaliar o desempenho dos modelos treinados.

### Modelos generativos
Para a gera√ß√£o dessas imagens, acredita-se que os modelos mais adequados sejam o Generative Adversarial Network (GAN) e o Variational Autoencoder (VAE), uma vez que essas arquiteturas t√™m se mostrado eficazes na gera√ß√£o de dados sint√©ticos em cen√°rios semelhantes. O GAN √© conhecido por sua capacidade de criar imagens realistas, enquanto o VAE oferece uma abordagem mais interpret√°vel e robusta para a gera√ß√£o de varia√ß√µes plaus√≠veis dos dados.

### Workflow

O *workflow* a seguir apresenta as etapas necess√°rias para desenvolvimento de modelos de gera√ß√£o de sinais sint√©ticos no contexto de an√°lise de falhas.

![Workflow](./reports/figures/workflowPRPD.drawio.png)

## Experimentos, Resultados e Discuss√£o dos Resultados

### InfoGAN

O InfoGAN (*Information Maximizing Generative Adversarial Network*) √© uma varia√ß√£o do modelo GAN (*Generative Adversarial Network*) projetada para descobrir e manipular de forma n√£o supervisionada os fatores latentes interpret√°veis de um conjunto de dados. A arquitetura do InfoGAN inclui dois componentes principais: o gerador, respons√°vel por criar imagens sint√©ticas a partir de um vetor de ru√≠do combinado com 
ùëê ; e o discriminador, que, al√©m de diferenciar entre imagens reais e geradas, possui um cabe√ßalho adicional para estimar o vetor 
ùëê das imagens geradas. O objetivo √© treinar o sistema para que as imagens geradas n√£o apenas sejam indistingu√≠veis das reais, mas tamb√©m sejam condicionadas pelos valores do vetor 
ùëê. A figura a seguir ilustra a arquitetura do InfoGAN.

<figure>
  <img src="./reports/figures/infogan_architecture.png" alt="infogan1" width="50%" />
  <figcaption>Fonte: Sik-Ho Tsang  </figcaption>
</figure>

Infelizmente, para o problema proposto, n√£o foi poss√≠vel gerar imagens com boas resolu√ß√µes utilizando o InfoGAN. Al√©m disso, o modelo apresentou colapso nas √©pocas iniciais, comprometendo a converg√™ncia do treinamento e a qualidade das imagens produzidas. Como √© poss√≠vel observar nas imagens seguintes.

<div style="display: flex; justify-content: space-between;">
<img src="./reports/figures/infogan-epoch66.png" alt="infogan1" width="50%" />
<img src="./reports/figures/infogan-epoch83.png" alt="infogan2" width="50%" />
</div>

Al√©m disso, o modelo apresentou colapso nas √©pocas iniciais, como observado na Figura abaixo, que mostra a evolu√ß√£o das perdas do gerador e do discriminador durante o treinamento. O aumento inst√°vel da perda do gerador por volta da √©poca 40, acompanhado de uma perda quase constante do discriminador, evidencia dificuldades de converg√™ncia e a incapacidade do modelo de equilibrar o aprendizado entre os componentes, comprometendo a qualidade das imagens geradas.

<img src="./reports/figures/loss_infogan.png" alt="infogan2" width="50%" />

### Difussion Model

Os Diffusion Models s√£o modelos generativos que aprendem a criar dados a partir de ru√≠do puro. A ideia principal √© inverter um processo de difus√£o: enquanto o processo direto (ou forward process) adiciona ru√≠do progressivamente aos dados, o modelo aprende a reconstruir os dados removendo o ru√≠do passo a passo, no processo inverso.

No caso de Conditioned Diffusion Models, o modelo √© treinado com condicionamento adicional. No nosso caso, seriam os r√≥tulos das imagens PRPD. Infelizmente, como √© poss√≠vel visualizar na imagem a seguir, os resultados apresentados n√£o foram conforme era esperado.

<img src="./reports/figures/Diffusion.png" alt="diffusion" width="50%" />

O gr√°fico abaixo mostra a curva de perda (loss) durante o treinamento. Ele ilustra como o modelo reduz gradualmente o erro em cada itera√ß√£o, demonstrando aprendizado ao longo do tempo.

<img src="./reports/figures/loss_diffusion.png" alt="diffusion" width="50%" />

Como podemos ver, a perda diminui consistentemente, indicando que o modelo est√° aprendendo a reconstruir os dados a partir do ru√≠do. No entanto, talvez fosse necess√°rio maior poder computacional para conseguir resultados satisfat√≥rios. 

### ACWGAN-SN

O modelo que consiguiu obter resultados satisfat√≥rios foi uma vers√£o da ACGAN com penalidade de gradiente de Wasserstein no Discriminador e normaliza√ß√£o espectral no Gerador.

![ACWGAN-SN](./reports/figures/ACGAN_schematic.png)

As fun√ß√µes de perda para o gerador e o discriminador foram os seguintes:

$L_{\text{CE}} = - \sum_{i=1}^{C} y_i \log(\hat{y}_i)$

$L_{D}^{ACWGAN} = -\mathbb{E}_{x \sim p_{d}}[D(x)] + \mathbb{E}_{\hat{z} \sim p_{g}}[D(\hat{x})] + \lambda\mathbb{E}_{\hat{x} \sim p_{g}} \left[(\| \nabla D(\alpha{x} + (1-\alpha\hat{x}) \|_2 - 1)^2 \right] + \lambda_{cls}{L_{\text{CE}}{(D_{aux}(x),C))}} + {L_{\text{CE}}{(D_{aux}(\hat{x}),\hat{C}))}}$

$L_{G}^{ACWGAN} = -\mathbb{E}_{\hat{z} \sim p_{g}}[D(\hat{x})] + {L_{\text{CE}}{(D_{aux}(\hat{x}),\hat{C}))}}$


#### Modelo Original

##### Gerador
| Component       | Details                                                                                                 |
|------------------|--------------------------------------------------------------------------------------------------------|
| Embedding       | Sequential: Embedding(3, 10), GaussianNoise()                                                          |
| FC Embedding    | Linear(in_features=10, out_features=256, bias=False)                                                   |
| FC Latent       | Sequential: GaussianNoise(), Linear(in_features=256, out_features=400, bias=False)                     |
| Block C1        | spectral_norm<br>ConvTranspose2d(400, 256, kernel_size=(4, 4), stride=(4, 4), bias=False)<br>BatchNorm2d(256)<br>ReLU()  |
| Block C2        | spectral_norm<br>ConvTranspose2d(256, 128, kernel_size=(8, 8), stride=(4, 4), padding=(2, 2), bias=False)<br>BatchNorm2d(128)<br>ReLU() |
| Block C3        | spectral_norm<br>ConvTranspose2d(128, 64, kernel_size=(8, 8), stride=(4, 4), padding=(2, 2), bias=False)<br>BatchNorm2d(64)<br>ReLU()  |
| Block C4        | spectral_norm<br>ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)<br>BatchNorm2d(32)<br>ReLU()  |
| Block C5        | spectral_norm<br>ConvTranspose2d(32, 3, kernel_size=(4, 3), stride=(2, 3), padding=(1, 26))<br>Tanh()                   |
| Parameters      | **4399713**                       

##### Discriminador

| Component       | Details                                                                                                 |
|------------------|--------------------------------------------------------------------------------------------------------|
| Block C1        | GaussianNoise()<br>Conv2d(3, 32, kernel_size=(8, 8), stride=(4, 4), padding=(2, 2), bias=False)<br>LeakyReLU()<br>Dropout2d() |
| Block C2        | GaussianNoise()<br>Conv2d(32, 64, kernel_size=(8, 8), stride=(4, 4), padding=(2, 2), bias=False)<br>LeakyReLU()<br>Dropout2d() |
| Block C3        | GaussianNoise()<br>Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)<br>LeakyReLU()<br>Dropout2d() |
| Block C4        | GaussianNoise()<br>Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)<br>LeakyReLU()<br>Dropout2d() |
| Block C5        | GaussianNoise()<br>Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)<br>LeakyReLU()<br>Dropout2d() |
| Block Dis       | GaussianNoise()<br>Linear(in_features=2048, out_features=1, bias=True)                                 |
| Block Aux       | GaussianNoise()<br>Linear(in_features=2048, out_features=3, bias=True)                                 |
| Parameters      | **2897924**                                                                                            |


#### Hiperpar√¢metros

Os hiperpar√¢metros que foram usados durante o treinamento s√£o os seguintes:

- (&beta;<sub>1</sub>, &beta;<sub>2</sub>) = (0, 0.999)
- batch size = 64
- epochs = 3000
- &lambda; = 10
- $\lambda_{cls}$ = 20 
- lr = 0.0002
- n embedding = 10
- z dimm = 256
- Gaussian Noise std = 0.1
- noise decay = 0.995
- Dropout rate = 0.5
- Leaky ReLU slope = 0.2
- Batch size = 64
- Tamanho das imagens = (256, 332, 3)

#### Ablation Study

Como foi analisado que o modelo ACWGAN-SN com diversos ru√≠dos apresentou resultados satisfat√≥rios, foi visto que poder√≠amos melhor√°-lo retirando cada um dos componentes em um experimento e avaliando, ao final, qual foi a melhor situa√ß√£o. Esse processo √© conhecido como ablation study. Foram estudadas 4 situa√ß√µes:

- Normaliza√ß√£o espectral
- Penaliza√ß√£o por Wasserstein
- Ru√≠do gaussiano no discriminador
- Ru√≠do gaussiano no gerador

Esses experimentos visaram entender a contribui√ß√£o de cada componente para o desempenho geral do modelo e verificar se a remo√ß√£o de algum deles poderia resultar em uma melhoria ou degrada√ß√£o do desempenho.

#### Modelo Original

A seguir, apresentamos a visualiza√ß√£o dos dados usando t-SNE, que mostra a distribui√ß√£o global das amostras geradas. Essa visualiza√ß√£o ajuda a entender a separa√ß√£o entre as diferentes classes e a qualidade da gera√ß√£o de dados.

<img src="./reports/figures/tSNE_ACWGAN_Full.png" width="50%">

Al√©m da visualiza√ß√£o global, realizamos o t-SNE individualizado por classe, permitindo uma an√°lise mais detalhada de como o modelo se comporta em rela√ß√£o a cada tipo de dado. Isso √© importante para avaliar se o modelo est√° conseguindo gerar amostras de alta qualidade para cada classe individualmente.

<img src="./reports/figures/tSNE_ACWGAN_perClass_Full.png" width="50%">

A tabela a seguir apresenta as m√©tricas geradas durante os experimentos, com dados de treino, valida√ß√£o e teste. As m√©tricas incluem FID, KID, precis√£o e recall para cada conjunto de dados e para cada classe. As classes s√£o indicadas por n√∫meros: 1 para coroa, 2 para interno e 3 para superf√≠cie.

|    | FID        | KID      | P&R           | FID1       | FID2       | FID3       | KID1      | KID2      | KID3      | P&R1         | P&R2         | P&R3         | MOD3 |
|---------|------------|----------|---------------|------------|------------|------------|-----------|-----------|-----------|---------------|---------------|---------------|------|
| Train   | 159.71 | 0.105 | (0.0049,0.0000) | 172.674213 | 184.229298 | 207.838089 | 0.135167  | 0.127615  | 0.176035  | (0.0000,0.0000) | (0.0059,0.0000) | (0.0215,0.0000) |      |
| Val     | 174.95 | 0.094 | (0.5967,0.0000) | 176.923227 | 202.807142 | 240.696508 | 0.128564  | 0.099677  | 0.183579  | (0.7175,0.0000) | (0.8754,0.0000) | (0.7147,0.0000) |      |
| Test    | 221.68 | 0.179 | (0.0010,0.0000) | 265.188173 | 283.617005 | 266.801814 | 0.344515  | 0.302050  | 0.299347  | (0.0000,0.0000) | (0.0000,0.0000) | (0.0031,0.0000)|      |

Por fim, apresentamos imagens geradas sinteticamente pelo modelo, uma para cada classe (coroa, interno e superf√≠cie). Essas imagens ilustram a capacidade do modelo de gerar dados realistas que correspondem a cada classe espec√≠fica.

<div style="display: flex; justify-content: space-between;">
    <div>
        <h5>Defeito de Coroa</h5>
        <img src="./reports/figures/syn-ACWGAN_full/synthetic_corona_292.png" alt="corona_no_gaussiannoisedis">
    </div>
    <div>
        <h5>Defeito Interno</h5>
        <img src="./reports/figures/syn-ACWGAN_full/synthetic_internal_41.png" alt="internal_no_spectralnorm">
    </div>
    <div>
        <h5>Defeito de Superf√≠cie</h5>
        <img src="./reports/figures/syn-ACWGAN_full/synthetic_surface_364.png" alt="surface_no_spectralnorm">
    </div>
</div>

#### Penaliza√ßao por Wasserstein
A seguir, mostramos a visualiza√ß√£o global das amostras geradas usando t-SNE.
<img src="./reports/figures/tSNE_ACWGAN_noGP.png" width="50%">

Ap√≥s, apresentamos a distribui√ß√£o das classes individualmente usando t-SNE.

<img src="./reports/figures/tSNE_ACWGAN_perClass_noGP.png" width="50%">

Aqui est√£o as m√©tricas geradas para as diferentes fases do treinamento, valida√ß√£o e teste.
|         | FID        | KID      | P&R           | FID1       | FID2       | FID3       | KID1      | KID2      | KID3      | P&R1         | P&R2         | P&R3         | MOD3 |
|---------|------------|----------|---------------|------------|------------|------------|-----------|-----------|-----------|---------------|---------------|---------------|------|
| Train   | 290.60     | 0.268    | (0.0000,0.0000) | 280.444725 | 288.940699 | 309.726250 | 0.313640  | 0.282250  | 0.325883  | (0.0000,0.0000) | (0.0000,0.0000) | (0.0000,0.0000) |      |
| Val     | 293.99     | 0.265    | (0.0000,0.0000) | 287.282253 | 299.069478 | 313.793774 | 0.333442  | 0.264077  | 0.328807  | (0.6406,0.0000) | (0.9781,0.0345) | (0.7117,0.0714) |      |
| Test    | 288.49     | 0.302    | (0.0000,0.0000) | 241.880872 | 321.797007 | 316.801898 | 0.365371  | 0.445290  | 0.440961  | (0.0000,0.0000) | (0.0000,0.0000) | (0.0000,0.0000) |      |

<div style="display: flex; justify-content: space-between;">
    <div>
        <h5>Defeito de Coroa</h5>
        <img src="./reports/figures/syn-ACWGAN_noGP/synthetic_corona_1.png" alt="corona_no_gaussiannoisedis">
    </div>
    <div>
        <h5>Defeito Interno</h5>
        <img src="./reports/figures/syn-ACWGAN_noGP/synthetic_internal_1.png" alt="internal_no_spectralnorm">
    </div>
    <div>
        <h5>Defeito de Superf√≠cie</h5>
        <img src="./reports/figures/syn-ACWGAN_noGP/synthetic_surface_1.png" alt="surface_no_spectralnorm">
    </div>
</div>


#### Ru√≠do Gaussiano no Discriminador
A seguir, mostramos a visualiza√ß√£o global das amostras geradas usando t-SNE.
<img src="./reports/figures/t_SNE_Visualization___With_post_processing___Without_Gaussian_Noise.png" width="50%">

Ap√≥s, apresentamos a distribui√ß√£o das classes individualmente usando t-SNE.

<img src="./reports/figures/t-SNE_Visualization_per_Class-Without_Gaussian_Noise.png" width="50%">

Aqui est√£o as m√©tricas geradas para as diferentes fases do treinamento, valida√ß√£o e teste.

|    | FID        | KID      | P&R           | FID1       | FID2       | FID3       | KID1      | KID2      | KID3      | P&R1         | P&R2         | P&R3         | MOD3 |
|---------|------------|----------|---------------|------------|------------|------------|-----------|-----------|-----------|---------------|---------------|---------------|------|
| Train   | 143.241.037 | 0.086224 | (0.2832,0.0013) | 183.954.051 | 180.917.254 | 163.615.821 | 0.144840 | 0.113382 | 0.124975 | (0.3607,0.0000) | (0.2751,0.0000) | (0.1617,0.0000) |      |
| Val     | 168.473.768 | 0.084379 | (0.6250,0.0118) | 216.852.641 | 217.768.535 | 194.649.687 | 0.165530 | 0.099961 | 0.118446 | (0.9648,0.0000) | (0.7679,0.0000) | (0.6377,0.0000) |      |
| Test    | 192.640.402 | 0.134054 | (0.0127,0.0000) | 284.380.472 | 248.441.158 | 212.888.935 | 0.369825 | 0.205304 | 0.214673 | (0.0000,0.0000) | (0.0000,0.0000) | (0.0000,0.0000) |      |

Abaixo est√£o as imagens geradas para cada classe.


<div style="display: flex; justify-content: space-between;">
    <div>
        <h5>Defeito de Coroa</h5>
        <img src="./reports/figures/syn-ACWGAN_no_gaussian_noise_dis/corona/synthetic_corona_220.png" alt="corona_no_gaussiannoisedis">
    </div>
    <div>
        <h5>Defeito Interno</h5>
        <img src="./reports/figures/syn-ACWGAN_no_gaussian_noise_dis/internal/synthetic_internal_41.png" alt="internal_no_spectralnorm">
    </div>
    <div>
        <h5>Defeito de Superf√≠cie</h5>
        <img src="./reports/figures/syn-ACWGAN_no_gaussian_noise_dis/surface/synthetic_surface_205.png" alt="surface_no_spectralnorm">
    </div>
</div>

#### Ru√≠do Gaussiano no Gerador
A seguir, mostramos a visualiza√ß√£o global das amostras geradas usando t-SNE.
<img src="./reports/figures/tSNE_ACWGAN_noGNoise.png" width="50%">

Ap√≥s, apresentamos a distribui√ß√£o das classes individualmente usando t-SNE.
<img src="./reports/figures/tSNE_ACWGAN_perClass_noGNoise.png" width="50%">

Aqui est√£o as m√©tricas geradas para as diferentes fases do treinamento, valida√ß√£o e teste.

|    | FID        | KID      | P&R           | FID1       | FID2       | FID3       | KID1      | KID2      | KID3      | P&R1         | P&R2         | P&R3         | MOD3 |
|---------|------------|----------|---------------|------------|------------|------------|-----------|-----------|-----------|---------------|---------------|---------------|------|
| Train   | 164.65 | 0.108 | (0.0020,0.0000) | 159.649909 | 194.616374 | 219.718140 | 0.132975  | 0.139477  | 0.194397  | (0.0000,0.0000) | (0.0000,0.0000) | (0.0199,0.0000) |      |
| Val     | 183.46 | 0.102 | (0.5410,0.0118) | 178.491791 | 212.824949 | 247.799486 | 0.140242  | 0.112723  | 0.199009  | (0.7049,0.0000) | (0.9045,0.0000) | (0.8046,0.0000) |      |
| Test    | 224.94 | 0.180 | (0.0000,0.0104) | 258.469314 | 275.457409 | 273.606913 | 0.324978  | 0.305368  | 0.317812  | (0.0000,0.0000) | (0.0000,0.0312) | (0.0000,0.0000) |      |

<div style="display: flex; justify-content: space-between;">
    <div>
        <h5>Defeito de Coroa</h5>
        <img src="./reports/figures/syn-ACWGAN_noGNoise/synthetic_corona_152.png" alt="corona_no_gaussiannoisedis">
    </div>
    <div>
        <h5>Defeito Interno</h5>
        <img src="./reports/figures/syn-ACWGAN_noGNoise/synthetic_internal_7.png" alt="internal_no_spectralnorm">
    </div>
    <div>
        <h5>Defeito de Superf√≠cie</h5>
        <img src="./reports/figures/syn-ACWGAN_noGNoise/synthetic_surface_92.png" alt="surface_no_spectralnorm">
    </div>
</div>

#### Normaliza√ßao Espectral
A seguir, mostramos a visualiza√ß√£o global das amostras geradas usando t-SNE.
<img src="./reports/figures/t_SNE_Visualization___With_post_processing___Without_Spectral_Norm.png" width="50%">

Ap√≥s, apresentamos a distribui√ß√£o das classes individualmente usando t-SNE.
<img src="./reports/figures/t-SNE_Visualization_per_Class-Without_Spectral_Norm.png" width="50%">

Aqui est√£o as m√©tricas geradas para as diferentes fases do treinamento, valida√ß√£o e teste.
|  | FID        | KID      | P&R           | FID1       | FID2       | FID3       | KID1      | KID2      | KID3      | P&R1         | P&R2         | P&R3         | 
|---------|------------|----------|---------------|------------|------------|------------|-----------|-----------|-----------|---------------|---------------|---------------|
| Train   | 170.996.605 | 0,102736 | (0.2812,0.0000) | 293.775.102 | 232.025.363 | 245.501.314 | 0,362067 | 0,203655 | 0,273549 | (0.0000,0.0000) | (0.0031,0.0000) | (0.0000,0.0000) |      
| Val     | 191.818.868 | 0,100242 | (0.4736,0.0000) | 212.507.233 | 228.128.554 | 238.886.100 | 0,168298 | 0,119335 | 0,175691 | (0.7160,0.0000) | (0.8696,0.0000) | (0.4636,0.0000) |      
| Test    | 208.008.298 | 0,150208 | (0.0020,0.0000) | 185.499.858 | 201.195.731 | 216.606.640 | 0,153220 | 0,139393 | 0,178365 | (0.5136,0.0000) | (0.2453,0.0000) | (0.0054,0.0000) |      

##### Resultados do Defeito de Coroa

<div style="display: flex; justify-content: space-between;">
    <div>
        <h5>Defeito de Coroa</h5>
        <img src="./reports/figures/syn-ACWGAN_no_spectral_norm/corona/synthetic_corona_7.png" alt="corona_no_spectralnorm">
    </div>
    <div>
        <h5>Defeito Interno</h5>
        <img src="./reports/figures/syn-ACWGAN_no_spectral_norm/internal/synthetic_internal_212.png" alt="internal_no_spectralnorm">
    </div>
    <div>
        <h5>Defeito de Superf√≠cie</h5>
        <img src="./reports/figures/syn-ACWGAN_no_spectral_norm/surface/synthetic_surface_212.png" alt="surface_no_spectralnorm">
    </div>
</div>

#### Compara√ß√£o dos modelos

M√©tricas no conjunto de Valida√ß√£o

| Modelo   | FID        | KID      | P&R           | FID1       | FID2       | FID3       | KID1      | KID2      | KID3      | P&R1         | P&R2         | P&R3         |
|---------|------------|----------|---------------|------------|------------|------------|-----------|-----------|-----------|---------------|---------------|---------------|
| Original     | 174.95 | 0.094 | (0.5967,0.0000) | **176.923227** | **202.807142** | 240.696508 | **0.128564**  | **0.099677**  | 0.183579  | (0.7175,0.0000) | (0.8754,0.0000) | (0.7147,0.0000) |      |
| Sem PG     | 293.99     | 0.265    | (0.0000,0.0000) | 287.282253 | 299.069478 | 313.793774 | 0.333442  | 0.264077  | 0.328807  | (0.6406,0.0000) | (**0.9781**,**0.0345**) | (0.7117,**0.0714**) |      |
| Sem Ru√≠do no Discriminador     | **168.473768** | **0.084379** | (**0.6250**,**0.0118**) | 216.852.641 | 217.768.535 | **194.649.687** | 0.165530 | **0.099961** | **0.118446** | (**0.9648**,0.0000) | (0.7679,0.0000) | (0.6377,0.0000) |      |
| Sem Ru√≠do no Gerador    | 183.46 | 0.102 | (0.5410,**0.0118**) | 178.491791 | 212.824949 | 247.799486 | 0.140242  | 0.112723  | 0.199009  | (0.7049,0.0000) | (0.9045,0.0000) | (**0.8046**,0.0000) |      |
| Sem Normaliza√ßao Espectral     | 191.818.868 | 0,100242 | (0.4736,0.0000) | 212.507.233 | 228.128.554 | 238.886.100 | 0,168298 | 0,119335 | 0,175691 | (0.7160,0.0000) | (0.8696,0.0000) | (0.4636,0.0000) |      


M√©tricas no conjunto de Teste
| Modelo   | FID        | KID      | P&R           | FID1       | FID2       | FID3       | KID1      | KID2      | KID3      | P&R1         | P&R2         | P&R3         |
|---------|------------|----------|---------------|------------|------------|------------|-----------|-----------|-----------|---------------|---------------|---------------|
| Original    | 221.68 | 0.179 | (0.0010,0.0000) | 265.188173 | 283.617005 | 266.801814 | 0.344515  | 0.302050  | 0.299347  | (0.0000,0.0000) | (0.0000,0.0000) | (**0.0031**,0.0000)|      |
| Sem PG   | 288.49     | 0.302    | (0.0000,0.0000) | 241.880872 | 321.797007 | 316.801898 | 0.365371  | 0.445290  | 0.440961  | (0.0000,0.0000) | (0.0000,0.0000) | (0.0000,0.0000) |      |
| Sem Ru√≠do no Discriminador    | **192.640** | **0.134054** | (**0.0127**,0.0000) | 284.380.472 | 248.441.158 | **212.888.935** | 0.369825 | 0.205304 | 0.214673 | (0.0000,0.0000) | (0.0000,0.0000) | (0.0000,0.0000) |      |
| Sem Ru√≠do no Gerador    | 224.94 | 0.180 | (0.0000,**0.0104**) | 258.469314 | 275.457409 | 273.606913 | 0.324978  | 0.305368  | 0.317812  | (0.0000,0.0000) | (0.0000,**0.0312**) | (0.0000,0.0000) |      |
| Sem Normaliza√ß√£o Espectral    | 208.01 | 0,150 | (0.0020,0.0000) | **185.50** | **201.195731** | 216.606.640 | **0,153220** | **0,139393** | **0,178365** | (**0.5136**,0.0000) | (**0.2453**,0.0000) | (**0.0054**,0.0000) |      

### Pegadas de Carbono

O Wandb foi usado como uma ferramenta de monitoramento para ter um controle sobre as m√©tricas de treinamento e os recursos de computador usados. Para obter uma aproxima√ß√£o do uso total de energia da GPU, a m√©dia do uso de energia da GPU por execu√ß√£o de treinamento foi obtida e, em seguida, multiplicada pelo n√∫mero total de horas de treinamento.

- Uso total de energia da GPU: 5,7 kW
- Tempo total de treinamento: 241,34 horas

√â importante levar em conta que algumas execu√ß√µes de experimentos n√£o mediram os recursos do computador, de modo que os recursos computacionais necess√°rios mostrados est√£o na extremidade abaixo da medida real. Em itera√ß√µes futuras, ser√° dada mais aten√ß√£o neste detalhe.  


## Conclus√£o

O projeto proposto aborda a gera√ß√£o sint√©tica de imagens de PRPD como uma solu√ß√£o para a escassez de bases de dados de alta qualidade e volume, necess√°rias para o treinamento de modelos de deep learning no diagn√≥stico de falhas em motores el√©tricos. A metodologia se apoia em modelos generativos, como GANs e VAEs, com o objetivo de aumentar a diversidade e a quantidade de dados dispon√≠veis. Para isso, utilizou-se um conjunto de dados real sobre descargas parciais.

Ap√≥s uma explora√ß√£o detalhada da base de dados, identificaram-se caracter√≠sticas relevantes, como textura e contornos, que evidenciam a complexidade das imagens de PRPD. Durante o desenvolvimento, a implementa√ß√£o de uma variante da GAN (ACWGAN-SN) foi bem-sucedida, gerando imagens sint√©ticas de boa qualidade. Contudo, os modelos InfoGAN e Diffusion n√£o apresentaram desempenhos satisfat√≥rios. Entre os principais desafios enfrentados por esses modelos, destacam-se a quantidade elevada de dados sint√©ticos, limita√ß√µes nas arquiteturas e restri√ß√µes de poder computacional, que impactaram negativamente os resultados.

Um dos destaques do projeto foi o estudo de abla√ß√£o, que trouxe contribui√ß√µes importantes para a compreens√£o do desempenho dos modelos. Esse estudo revelou que a configura√ß√£o Sem Ru√≠do no Discriminador e Sem Normaliza√ß√£o Espectral foi determinante para o sucesso do ACWGAN, que se mostrou a abordagem mais robusta e eficaz at√© o momento.

Embora ainda haja espa√ßo para melhorias e otimiza√ß√µes, os resultados obtidos com o ACWGAN indicam o potencial de modelos generativos na gera√ß√£o de dados sint√©ticos de PRPD. Assim, espera-se que a continuidade do trabalho permita avan√ßos significativos na variabilidade dos dados, contribuindo para diagn√≥sticos mais precisos e eficientes no futuro.

## Refer√™ncias Bibliogr√°ficas
1. Lv, F., Liu, G., Wang, Q., Lu, X., Lei, S., Wang, S., & Ma, K. (2023). Pattern Recognition of Partial Discharge in Power Transformer Based on InfoGAN and CNN. Journal of Electrical Engineering & Technology, 18(2), 829‚Äì841. https://doi.org/10.1007/s42835-022-01260-7
2. Guo, B., Li, S., Li, N., & Li, P. (2021). A GAN-based Method for the Enhancement of Phase-Resolved Partial Discharge Map Data. Forest Chemicals Review, 1484, 1484‚Äì1497.
3. Zhu, G., Zhou, K., Lu, L., Fu, Y., Liu, Z., & Yang, X. (2023). Partial Discharge Data Augmentation Based on Improved Wasserstein Generative Adversarial Network With Gradient Penalty. IEEE Transactions on Industrial Informatics, 19(5), 6565‚Äì6575. https://doi.org/10.1109/TII.2022.3197839
