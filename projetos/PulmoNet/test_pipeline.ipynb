{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definições iniciais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from scipy.linalg import sqrtm\n",
    "from tqdm import trange\n",
    "import random\n",
    "random.seed(5)\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import lungCTData\n",
    "from model import Generator\n",
    "from metrics import calculate_fid, FeatureExtractor, get_features\n",
    "from metrics import my_ssim, crop_center_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#device = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustar isso aqui para pasta com dados de teste\n",
    "processed_data_folder = '/mnt/shared/ctdata_thr25'\n",
    "#path to model\n",
    "trained_gen_path = './model_thr_25k/models/model_thr_25k_gen_trained.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = lungCTData(processed_data_folder=processed_data_folder,mode='test',start=20000,end=21000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = Generator()\n",
    "gen.load_state_dict(torch.load(trained_gen_path, weights_only=True))\n",
    "gen.to(device)\n",
    "gen.eval()\n",
    "batch_size = 10\n",
    "data_loader_test = DataLoader(dataset_test, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calcula o FID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/leticia/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    }
   ],
   "source": [
    "# Define a rede Inception V3\n",
    "model_inception = torch.hub.load('pytorch/vision:v0.10.0', 'inception_v3', pretrained=True)\n",
    "model_inception.eval()\n",
    "\n",
    "# Define modelo para feature extraction\n",
    "feature_extractor = FeatureExtractor(model_inception)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gera dados sintéticos\n",
    "fake_data_imgs = np.empty((len(dataset_test),512,512))\n",
    "real_data_imgs = np.empty((len(dataset_test),512,512))\n",
    "fake_data_features = np.empty((len(dataset_test),2048))\n",
    "real_data_features = np.empty((len(dataset_test),2048))\n",
    "counter = 0\n",
    "with torch.no_grad():\n",
    "    for batch in data_loader_test:\n",
    "        input_img_batch = batch[0]\n",
    "        input_mask_batch = batch[1]\n",
    "        \n",
    "        input_img = input_img_batch.to(device)\n",
    "        input_mask = input_mask_batch.to(device)\n",
    "        \n",
    "        gen_img = gen(input_mask)\n",
    "        fake_data_imgs[counter*batch_size:(counter+1)*batch_size,:,:] = np.squeeze(gen_img.detach().cpu().numpy())\n",
    "        real_data_imgs[counter*batch_size:(counter+1)*batch_size,:,:] = np.squeeze(input_img.detach().cpu().numpy())\n",
    "\n",
    "        features_fake = get_features(feature_extractor, gen_img, choose_transform=2, device=device)\n",
    "        features_real = get_features(feature_extractor, input_img, choose_transform=2, device=device)\n",
    "        fake_data_features[counter*batch_size:(counter+1)*batch_size,:] = features_fake\n",
    "        real_data_features[counter*batch_size:(counter+1)*batch_size,:] = features_real\n",
    "        counter=counter+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID: 70.70\n"
     ]
    }
   ],
   "source": [
    "# Obtém as distribuições para os dados reais e sintéticos\n",
    "mu1, sigma1 = np.mean(np.squeeze(real_data_features),axis=0), np.cov(np.squeeze(real_data_features))\n",
    "mu2, sigma2 = np.mean(np.squeeze(fake_data_features),axis=0), np.cov(np.squeeze(fake_data_features))\n",
    "\n",
    "# Calcula o FID entre os dados reais e sintéticos\n",
    "fid_value = calculate_fid(mu1, sigma1, mu2, sigma2)\n",
    "print(f\"FID: {fid_value:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calcula o SSIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9198216603737535 0.05271807711304367\n"
     ]
    }
   ],
   "source": [
    "# Calcula SSIM entre dados reais e sintéticos\n",
    "ssim = np.zeros(len(dataset_test))\n",
    "luminance = np.zeros(len(dataset_test))\n",
    "contraste = np.zeros(len(dataset_test))\n",
    "struct_similarity = np.zeros(len(dataset_test))\n",
    "for i in range(len(dataset_test)):\n",
    "    ssim[i], luminance[i], contraste[i], struct_similarity[i] = my_ssim(np.squeeze(real_data_imgs[i]), np.squeeze(fake_data_imgs[i]), 0.01, 0.03, 0.03)\n",
    "\n",
    "print(np.mean(ssim), np.std(ssim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9271554151377082 0.05912170287379875\n"
     ]
    }
   ],
   "source": [
    "# Calcula SSIM entre dados reais e sintéticos\n",
    "ssim = np.zeros(len(dataset_test))\n",
    "luminance = np.zeros(len(dataset_test))\n",
    "contraste = np.zeros(len(dataset_test))\n",
    "struct_similarity = np.zeros(len(dataset_test))\n",
    "for i in range(len(dataset_test)):\n",
    "    ssim[i], luminance[i], contraste[i], struct_similarity[i] = my_ssim(np.squeeze(crop_center_array(real_data_imgs[i], 256, 256)), np.squeeze(crop_center_array(fake_data_imgs[i], 256, 256)), 0.01, 0.03, 0.03)\n",
    "\n",
    "print(np.mean(ssim), np.std(ssim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pulmonet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
