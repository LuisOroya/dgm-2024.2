# `PulmoNet: Rede Neuronal Generativa para Imagens Tomogr√°ficas Pulmonares`
# `PulmoNet: Generative Neuronal Network for Pulmonary Tomographic Images`

## Apresenta√ß√£o

O presente projeto foi originado no contexto das atividades da disciplina de p√≥s-gradua√ß√£o *IA376N - IA generativa: de modelos a aplica√ß√µes multimodais*, 
oferecida no segundo semestre de 2024, na Unicamp, sob supervis√£o da Profa. Dra. Paula Dornhofer Paro Costa, do Departamento de Engenharia de Computa√ß√£o e Automa√ß√£o (DCA) da Faculdade de Engenharia El√©trica e de Computa√ß√£o (FEEC).

 |Nome  | RA | Especializa√ß√£o|
 |--|--|--|
 | Arthur Matheus Do Nascimento | 290906 | Eng. El√©trica |
 | J√∫lia Castro de Paula | 219193 | Eng. El√©trica |
 | Let√≠cia Levin Diniz | 201438  | Eng. El√©trica |

## Resumo (Abstract)
As tomografias computadorizadas (CT) pulmonares e a segmenta√ß√£o das vias a√©reas desempenham um papel crucial no diagn√≥stico preciso de doen√ßas pulmonares. 
Prop√µe-se o desenvolvimento da PulmoNet, uma rede para s√≠ntese de imagens 2D de CTs pulmonares, com o intuito de apoiar redes de segmenta√ß√£o e gerar dados sint√©ticos para incorpora√ß√£o em bases de dados para outras redes neurais (e.g. classificadores de tumores).
Utilizando a base de dados ATM'22, implementa-se uma arquitetura GAN, sendo o gerador uma rede Pix2Pix e o discriminador uma PatchGAN, que receber√° uma m√°scara bin√°ria do pulm√£o e preencher√° esta fatia com as vias a√©reas.
Tal rede ser√° avaliada em tr√™s an√°lises: qualitativa (observa√ß√£o dos resultados no est√°gio inicial do projeto),  quantitativa (m√©tricas FID e SSIM) e utilidade (aplica√ß√£o do gerador como *feature extractor*).
Os resultados parciais at√© o momento n√£o foram bem-sucedidos, uma vez que se enfrenta problemas no treinamento, principalmente com rela√ß√£o a velocidade de aprendizado do discriminador comparada ao do gerador.

## Descri√ß√£o do Problema/Motiva√ß√£o
As tomografias computadorizadas (CT) pulmonares, juntamente com a segmenta√ß√£o das vias a√©reas, desempenham um papel crucial no diagn√≥stico preciso de doen√ßas pulmonares. Ao gerar imagens detalhadas da regi√£o tor√°cica, ela permite que m√©dicos mapeiem a anatomia das vias a√©reas antes de procedimentos cir√∫rgicos, avaliando a extens√£o de les√µes e facilitando o acompanhamento da progress√£o de doen√ßas respirat√≥rias [[2]](#2). Al√©m disso, a CT √© fundamental para monitorar a efic√°cia de tratamentos e detectar seus poss√≠veis efeitos colaterais [[5]](#5).

A complexidade e diversidade do corpo humano dificultam a obten√ß√£o de grandes volumes de dados m√©dicos para treinar modelos de aprendizado de m√°quina, como as redes neurais. Essa escassez de dados pode levar a diagn√≥sticos imprecisos, comprometendo a qualidade do atendimento aos pacientes [[6]](#6). Com as redes generativas √© poss√≠vel criar dados de forma a compensar essa escassez, permitindo que as redes aprendam muito mais detalhes do que utilizando apenas aqueles obtidos de exames reais.

[Link para o v√≠deo de apresenta√ß√£o E1](https://drive.google.com/file/d/1TlpQOlCh_lAI0-jPPMPWOzGZ_werCo3d/view?usp=sharing)

[Link para a apresenta√ß√£o de slides E1](https://docs.google.com/presentation/d/1b8W0Cw1eiTbWlJ0CJJ8eMRA4zyu2iLhYvggi55-mOb0/edit?usp=sharing)

[Link para a apresenta√ß√£o de slides E2](https://docs.google.com/presentation/d/1QH5_WpeTp7kQPSVB78ukK7msn-Tx09pZoM_3dWmeqC4/edit?usp=sharing)

## Objetivo
Este projeto visa gerar imagens sint√©ticas de tomografia computadorizada (CT) da regi√£o tor√°cica de alta fidelidade, tamb√©m produzindo m√°scaras de segmenta√ß√£o das vias a√©reas. A priori, o modelo generativo proposto ter√° como sa√≠da imagens em duas dimens√µes (2D) de CT da regi√£o do t√≥rax, com grau de realismo suficiente e que possa auxiliar redes de segmenta√ß√£o de vias a√©reas. 
Al√©m disso, este trabalho tamb√©m serve como uma primeira etapa de um projeto maior e mais ambicioso, no qual buscar-se-√° a gera√ß√£o de volumes (imagens 3D) de tomografias pulmonares, uma combina√ß√£o de fatias que juntas formar√£o o equivalente a um exame real.

## Metodologia
### Materiais de Refer√™ncia
Este projeto usar√° como inspira√ß√£o inicial o trabalho desenvolvido em [[1]](#1), o qual prop√µe duas arquiteturas baseadas em GANs para a s√≠ntese de imagens CT pulmonares a partir de m√°scaras bin√°rias que segmentam a regi√£o pulmonar. Das arquiteturas propostas, inspirar-se-√° na arquitetura Pix2Pix, na qual o gerador √© composto de um encoder que aumenta a profundidade da imagem enquanto diminui suas dimens√µes, seguido de um decoder que realiza o processo oposto. Tal arquitetura tamb√©m utiliza conex√µes residuais. Na arquitetura Pix2Pix, o discriminador √© composto por cinco camadas convolucionais, onde as quatro primeiras s√£o seguidas por uma camada de ativa√ß√£o *LeakyReLu*, enquanto a √∫ltima √© seguida de uma fun√ß√£o *sigmoide*. 

Al√©m do artigo [[1]](#1), tamb√©m ser√£o considerados os trabalhos realizados em [[3]](#3) e [[4]](#4). No primeiro, desenvolveu-se uma GAN condicional para a gera√ß√£o de imagens CT pulmonares a partir de imagens de resson√¢ncia magn√©tica. J√° no segundo, utiliza-se um modelo baseado em GAN para a segmenta√ß√£o do pulm√£o em imagens CT que cont√©m anomalias no tecido pulmonar. Apesar dos objetivos de tais trabalhos n√£o serem os mesmos objetivos propostos para o presente projeto, eles servir√£o de apoio para proposi√ß√£o de modifica√ß√µes na arquitetura, estrat√©gias de treino e de valida√ß√£o de resultados.   

### Modelo Proposto
Conforme j√° discutido na se√ß√£o anterior, ap√≥s um estudo de outros artigos correlatos ao nosso projeto, verificamos que a estrat√©gia predominante para a s√≠ntese de CTs pulmonares e convers√£o imagem para imagem corresponde a aplica√ß√£o de GANs (redes advers√°rias generativas).
Em uma GAN, temos uma rede neural "geradora", respons√°vel por sintetizar as distribui√ß√µes de entrada e retornar sa√≠das similares aos dados reais, e uma rede neural "discriminadora", que deve ser capaz de classificar corretamente suas entradas como "reais" ou "falsas". Com isso, uma boa rede generativa deve ser capaz de enganar o discriminador, ao passo que um bom discriminador deve identificar corretamente os dados sint√©ticos em meio aos dados reais.

No caso espec√≠fico da nossa aplica√ß√£o, utilizaremos como refer√™ncia principal as arquiteturas propostas em [[1]](#1). Neste trabalho, uma rede Pix2Pix √© utilizada pelo gerador, recebendo uma m√°scara bin√°ria com o formato de um pulm√£o em um CT e retornando esta imagem 2D preenchida com as vias a√©ras de um pulm√£o. J√° a rede discriminadora segue a arquitetura 30 √ó 30 PatchGAN. Ambas estas estruturas foram inicialmente recomendadas por [[8]](#8).
As duas imagens abaixo ilustram as arquiteturas do gerador e discriminador, respectivamente.

![Arquitetura Pix2Pix proposta para gerador.](figs/arquitetura_gen.png?raw=true)

*Figura 1: Arquitetura Pix2Pix proposta para gerador.*

![Arquitetura PatchGAN proposta para discriminador.](figs/arquitetura_disc.png?raw=true)

*Figura 2: Arquitetura PatchGAN proposta para discriminador.*

A fun√ß√£o de loss aplica o crit√©rio de *Binary Cross Entropy*, conforme a seguinte a equa√ß√£o matem√°tica:

$arg\ min_{ùê∫}\ max_{ùê∑}\ E_{ùë•,ùë¶}[log ùê∑(ùë•, ùë¶)] + E_{ùë•,ùëß}[log(1 ‚àí ùê∑(ùë•, ùê∫(ùë•, ùëß)))] + ùúÜE_{ùë•,ùë¶,ùëß}[‚Äñùë¶ ‚àí ùê∫(ùë•, ùëß)‚Äñ_{1}]$

### Bases de Dados e Evolu√ß√£o
Apesar de inspirar-se no artigo [[1]](#1), o desenvolvimento deste projeto utilizar√° a base de dados ATM'22, cuja descri√ß√£o est√° na tabela abaixo. Tal base de dados n√£o foi usada no desenvolvimento do projeto em [[1]](#1), mas foi escolhida no presente projeto devido a sua amplitude, a presen√ßa de dados volum√©tricos e em raz√£o das imagens possu√≠rem a delimita√ß√£o das vias a√©reas obtidas atrav√©s de especialistas. Os volumes da base ATM'22 foram adquiridos em diferentes cl√≠nicas e considerando diferentes contextos cl√≠nicos. Constru√≠da para a realiza√ß√£o de um desafio de segmenta√ß√£o autom√°tica de vias a√©ria utilizando IA, a base de dados est√° dividida em 300 volumes para treino, 50 para valida√ß√£o e 150 para teste.

|Base de Dados | Endere√ßo na Web | Resumo descritivo|
|----- | ----- | -----|
|ATM'22 | https://zenodo.org/records/6590774 e https://zenodo.org/records/6590775  | Esta base cont√©m 500 volumes CTs pulmonares, nos quais as vias a√©reas est√£o completamente anotadas, i.e., delimitadas. Tais volumes ser√£o fatiados em imagens 2-D, segmentados e transformados. Esta base de dados foi utilizada para um desafio de segmenta√ß√£o [[2]](#2).|

Os dados desta base s√£o arquivos com extens√£o *.nii.gz, e cont√™m todo o volume pulmonar obtido durante um exame de tomografia. Cada arquivo com um volume pulmonar √© acompanhado por um outro arquivo de mesma extens√£o contendo as anota√ß√µes feitas por especialistas.
Dado que este trabalho centrar√°-se na gera√ß√£o de imagens sint√©ticas em duas dimens√µes de CTs pulmonares, estes volumes pulmonares ser√£o fatiados no eixo transversal, assim como ilustrado na imagem abaixo. Como resultado, fatiaremos os 500 volumes pulmores em uma quantidade muito maior de imagens 2D, aumentando o tamanho dos conjuntos de dados dispon√≠veis para treinamento, valida√ß√£o e testes.

![Exemplo de fatia de CT pulmonar obtida a partir da base de dados ATM'22.](figs/dataset_exemplo_fatia.png?raw=true)

*Figura 3: Exemplo de fatia de CT pulmonar obtida a partir da base de dados ATM'22.*

A quantia exata de dados que ser√£o utilizados depende da configura√ß√£o da fatia obtida. Isto √©, n√£o ser√£o utilizadas todas as fatias do volume pulmonar, mas sim apenas as imagens que apresentarem o pulm√£o completo e cercado por tecidos. A partir desta condi√ß√£o, as fatias ser√£o selecionadas e utilizadas como entrada da rede geradora. Ressalta-se que esta sele√ß√£o √© necess√°ria, uma vez que √© uma restri√ß√£o da biblioteca em Python *lungmask* [[7]](#7), utilizada para segmenta√ß√£o autom√°tica de CTs pulmonares.
Tamb√©m √© pertinente destacar que esta segmenta√ß√£o √© uma etapa essencial do workflow, posto que os dados de entrada da rede geradora da GAN ser√£o m√°scaras pulmonares, tal como feito em [[1]](#1).

O gr√°fico abaixo ilustra o histograma da base de dados ap√≥s a sele√ß√£o das fatias. Para a constru√ß√£o deste histograma, calculou-se a quantidade de pixels de cada imagem que descrevem a regi√£o pulmonar (a parte em branco ap√≥s a m√°scara de segmenta√ß√£o). Nota-se que temos muitas imagens com at√© 2 mil pixels para compor o pulm√£o, depois temos uma queda nesta quantidade de imagens at√© algo em torno de 20 mil pixels, seguido por uma nova regi√£o de m√°ximo - temos a maior concentra√ß√£o das imagens usadas pela rede generativa com o pulm√£o ocupando entre 30 e 40 mil pixels. Depois disso, a quantidade exemplares com mais pixels vai diminuindo gradualmente at√© pouco mais de 100 mil pixels.
Um ponto importante a ser mencionado √© que apesar do histograma come√ßar em zero, a menor quantia de pixels no conjunto ap√≥s segmenta√ß√£o √© de 100 pixels. Ademais, dado que imagens 512 x 512 t√™m mais de 260 mil pixels, as imagens com a maior quantidade de pixels para a regi√£o do pulm√£o n√£o ocupam nem metade de todos os pixels da imagem.

![Histrograma da quantidade de pixels das fatias selcionadas ap√≥s segmenta√ß√£o das CTS pulmonares da base de dados ATM'22.](figs/histograma_fatias.png?raw=true)

*Figura 4: Histrograma da quantidade de pixels das fatias selcionadas ap√≥s segmenta√ß√£o das CTS pulmonares da base de dados ATM'22.*

A figura abaixo apresenta exemplos de fatias em regi√µes distintas deste histograma para podermos visualizar a variabilidade dos dados de entrada da rede.
Nota-se que as fatias com menos de 10 mil pixels para descrever o pulm√£o praticamente n√£o t√™m regi√£o suficiente para ser preenchida com vias a√©reas, ao passo que as imagens com mais pixels para a regi√£o do pulm√£o s√£o aquelas mais pr√≥ximas de uma fatia no meio do pulm√£o, exibindo a maior √°rea util deste √≥rg√£o.
Com base nestas an√°lises, considera-se descartar imagens com poucos pixels para o pulm√£o.

![Exemplos de fatias das CTS pulmonares da base de dados ATM'22 segmentadas.](figs/exemplos_pixels.png?raw=true)

*Figura 5: Exemplos de fatias das CTS pulmonares da base de dados ATM'22 segmentadas.*

Al√©m da segmenta√ß√£o dos dados e sele√ß√£o das fatias, a base de dados tamb√©m passa pelas etapas de normaliza√ß√£o e de transforma√ß√£o para *numpy arrays*, antes de ser utilizada pelas GANs implementadas neste projeto.

### Workflow
O fluxo de trabalho proposto por este projeto, ilustrado na figura a seguir, inicia-se com a obten√ß√£o da base de dados ATM'22 e seu devido tratamento, conforme detalhado na se√ß√£o anterior.
Utilizando estes dados, alimenta-se a rede generativa com as fatias segmentadas (m√°scaras bin√°rias). J√° a rede discriminadora recebe os dados reais (sem segmenta√ß√£o) e os dados sint√©ticos, devendo classificar cada um como "real" ou "falso".
Ap√≥s o treinamento, avalia-se os dados sint√©ticos a partir de tr√™s perspectivas: an√°lise qualitativa, an√°lise quantitativa e an√°lise de utilidade, as quais ser√£o descritas em detalhes nas pr√≥ximas se√ß√µes deste relat√≥rio.

![Fluxo para treinamento da PulmoNet.](figs/workflow_completo.png?raw=true)

*Figura 6: Fluxo para treinamento da PulmoNet.*

Destaca-se que, em opera√ß√£o (ap√≥s a fase treinamento), espera-se que o modelo receba m√°scaras bin√°rias com o formato do pulm√£o somadas a um ru√≠do, retonando o preenchimento da √°rea interna do pulm√£o.
Uma mesma m√°scara bin√°ria poder√° gerar imagens sint√©ticas distintas, devido ao ru√≠do aleat√≥rio adicionado na entrada do modelo.
Os dados sint√©ticos dever√£o ser bons o suficiente para ajudarem no treinamento de modelo de segmenta√ß√£o das vias a√©reas e potencialmente substituir o uso de dados reais, para a preserva√ß√£o da privacidade dos pacientes.

Ademais, na fase atual do projeto, ainda n√£o estamos somando um ru√≠do aleat√≥rio √†s fatias segmentadas na entrada do gerador, mas este passo est√° mapeado para as pr√≥ximas etapas do projeto.

### Ferramentas Relevantes
A ferramenta escolhida para o desenvolvimento da arquitetura dos modelos e de treinamento √© o **PyTorch**, em fun√ß√£o de sua relev√¢ncia na √°rea e familiaridade por parte dos integrantes do grupo.
Ademais, para o desenvolvimento colaborativo dos modelos entre os estudantes, opta-se pela ferramenta de programa√ß√£o **Google Collaboratory**.
J√° para o versionamento dos modelos e para ajustar seus hiperpar√¢metros, decidiu-se pela ferramenta **Weights & Biases (Wandb AI)** dentre as op√ß√µes dispon√≠veis no mercado. E, al√©m disso, a ferramenta do **GitHub** tamb√©m auxiliar√° no versionamento dos algoritmos desenvolvidos.

### M√©tricas de Avalia√ß√£o
Para avaliar a qualidade dos resultados obtidos com o modelo de s√≠ntese, prop√µe-se tr√™s tipos de avalia√ß√£o: an√°lise qualitativa, an√°lise quantitativa e an√°lise de utilidade.

#### An√°lise Qualitativa
Esta estrat√©gia ser√° utilizada apenas nas etapas iniciais do desenvolvimento do projeto, na qual os pr√≥prios estudantes ir√£o observar os resultados sint√©ticos, sejam eles imagens e/ou  volumes, e comparar√£o com os dados reais esperados. Com isto, faz-se uma avalia√ß√£o se a imagem gerada estaria muito distante de uma CT pulmonar ou se o modelo j√° estaria se encaminhando para bons resultados. Ap√≥s esta etapa, as avalia√ß√µes do modelo ser√£o feitas por meio das an√°lises quantitativa e de utiliddade.

#### An√°lise Quantitativa
A an√°lise quantitativa trata de uma avalia√ß√£o sobre as imagens a partir dos m√©todos **Fr√©chet Inception Distance (FID)** e **Structural Similarity Index (SSIM)**, os quais s√£o utilizados para avalia√ß√£o de qualidade das imagens sint√©ticas e de similaridade com dados reais. Ambas estrat√©gias foram utilizadas pelos pesquisadores do artigo [[1]](#1), o que permite uma avalia√ß√£o dos nossos resultados frente a esta outra pesquisa.

Entrando em mais detalhes, a m√©trica FID avalia o desempenho da rede generativa e ser√° calculada utilizando uma rede neural pr√©-treinada *InceptionV3*, que extrair√° *features* das fatias pulmonares geradas e das fatias originais. Com isso, as distribui√ß√µes dos dados sint√©ticos e dos dados reais, obtidas pelo encoder desta rede, s√£o usadas para calcular a FID e, assim, avaliar a qualidade da imagem gerada.
A express√£o matem√°tica que descreve o c√°lculo da FID entre duas distribui√ß√µes gaussianas criadas pelas *features* da √∫ltima camada de *pooling* do modelo *Inception-v3* √© dada por:

$FID = ‚Äñùúá_{ùëü} ‚àí ùúá_{ùëî}‚Äñ^{2} + Tr(\sum_{ùëü} + \sum_{ùëî} ‚àí 2(\sum_{ùëü}\sum_{ùëî})^{1‚àï2})$

onde $ùúá_{ùëü}$ e $ùúá_{ùëî}$ s√£o as m√©dias entre as imagens reais e sint√©ticas, e $\sum_{ùëü},\ \sum_{ùëî}$ s√£o as matrizes de convari√¢ncia para os vetores de *features* dos dados reais e gerados, respectivamente.
Quanto menor for o FID, maior a qualidade da imagem gerada.

Por sua vez, a m√©trica SSIM compara a imagem gerada com seu respectivo *ground-truth* com base em tr√™s caracter√≠sticas: lumin√¢ncia, distor√ß√£o de contraste e perda de correla√ß√£o estrutural.
Casos as imagens sejam iguais, o resultado desta m√©trica ser√° igual a 1, ao passo que se as imagens forem completamente diferentes, o SSIM ser√° nulo.
Ressalta-se que n√£o queremos que esta m√©trica fique em nenhum deste extremos, mas sim em um valor intermedi√°rio.
As express√µes matem√°ticas usadas para o c√°lculo desta m√©trica s√£o:

$SSIM(ùë•, ùë¶) = l(ùë•, ùë¶) \times ùëê(ùë•, ùë¶) \times ùë†(ùë•, ùë¶)$

$l(ùë•, ùë¶) = \frac{2ùúá_{ùë•}ùúá_{ùë¶} + ùê∂_{1}}{ùúá^{2}_{ùë•}+ ùúá^{2}_{ùë¶} + ùê∂_{1}}$

$ùëê(ùë•, ùë¶) = \frac{2ùúé_{ùë•}ùúé_{ùë¶} + ùê∂_{2}}{ùúé^{2}_{ùë•} + ùúé^{2}_{ùë¶} + ùê∂_{2}}$

$ùë†(ùë•, ùë¶) = \frac{ùúé_{ùë•ùë¶} + ùê∂_{3}}{ùúé_{ùë•}ùúé_{ùë¶} + ùê∂_{3}}$

onde $ùúá_{ùë•}$, $ùúá_{ùë¶}$, $ùúé_{ùë•}$, $ùúé_{ùë¶}$, e $ùúé_{ùë•ùë¶}$ s√£o as m√©dias locais, vari√¢ncias e covari√¢ncias cruzadas para as imagens ùë•, ùë¶, respectivament. $ùê∂_{1}$, $ùê∂_{2}$ $ùê∂_{3}$ s√£o constantes.

#### An√°lise de Utilidade
Dado que o objetivo do projeto √© gerar imagens sint√©ticas (2D) de CTs pulmonares realistas, avalia-se nesta etapa duas perspectivas. A primeira delas trata da segmenta√ß√£o das fatias sint√©ticas por meio da biblioteca *lungmask* e compara√ß√£o desta sa√≠da com a m√°scara bin√°ria original que gerou esta imagem sint√©tica. Isto √© feito para avaliar se o gerador conseguiu manter o formato do pulm√£o original ou algo pr√≥ximo a isso. Utiliza-se o SSIM para compara√ß√£o destas duas fatias pulmonares segmentadas.

J√° a segunda perspectiva trata da utilidade do gerador, em termos de **feature extraction**. Isto √©, tomando como inspira√ß√£o a abordagem explorada em [[9]](#9), implementaremos uma U-Net, com a mesma estrutura da rede geradora Pix2Pix da PulmoNet, para realizar a segmenta√ß√£o das vias a√©reas e compararemos o desempenho desta U-Net com uma outra rede que utiliza as *features* extra√≠das pelo nosso gerador. Esta compara√ß√£o ser√° avaliada ao comparar as sa√≠das com a pr√≥pria segmenta√ß√£o presente na base de dados ATM'22, feita por especialistas. Al√©m disso, ser√° calculado o coeficiente DICE (obtido a partir da precis√£o e *recall* da predi√ß√£o), tomando como refer√™ncia o artigo [[2]](#2), e considera-se tamb√©m calcular o tempo de processamento das redes U-Net e U-Net com *features* extra√≠dos pela nossa Pix2Pix, a fim de verificar se tamb√©m h√° uma otimiza√ß√£o neste quesito.

Por fim, √© importante destacar o caminho a ser seguido para a avalia√ß√£o da rede generativa para as sa√≠das em 3D, caso seja poss√≠vel implement√°-las dentro do prazo do projeto. Para esta aplica√ß√£o, utilizar√≠amos 5 fatias de CTs pulmonares sequenciais, remover√≠amos a segunda e a quarta fatias e sinetizar√≠amos esas fatias faltantes. Feito isso, analisar√≠amos o volume formado em compara√ß√£o com o volume original. Com isso, seria poss√≠vel avaliar se a PulmoNet √© capaz de gerar imagens relevantes e realistas, al√©m de possibilitar sua implementa√ß√£o no aux√≠lio a **interpola√ß√£o de CTs pulmonares**.

### Cronograma
O projeto ser√° implementado seguindo o seguinte fluxo l√≥gico:

![Fluxo l√≥gico das ativaidades para desenvolvimento da PulmoNet.](figs/fluxo_logico.png?raw=true)

*Figura 7: Fluxo l√≥gico das ativaidades para desenvolvimento da PulmoNet.*

Dado este fluxo, estipulamos o seguinte cronograma para desenvolvimento do projeto:

| N¬∫ da Tarefa | Descri√ß√£o                                                                 | Data Prevista de Finaliza√ß√£o | Semanas Entre Etapas |
|--------------|---------------------------------------------------------------------------|------------------------------|----------------------|
| 1            | Leitura de artigos, familiariza√ß√£o com a base de dados e GANs             | 10/09                        |                      |
| 2            | Primeira vers√£o da GAN (inspirada no artigo de refer√™ncia)                | 24/09                        | 2 semanas            |
| 3            | Estrutura de avalia√ß√£o bem delimitada                                     | 07/10                        | 2 semanas            |
| 4            | E2                                                                        | 08/10                        | 1 dia                |
| 5            | Primeiros resultados com imagens segmentadas e valores para valida√ß√£o     | 15/10                        | 1 semana             |
| 6            | Fine-tuning e aperfei√ßoamento do modelo                                   | 29/10                        | 2 semanas            |
| 7            | Evoluir para redes 3D ou continuar aperfei√ßoando o modelo                 | 05/11                        | 1 semana             |
| 8            | E3                                                                        | 25/11                        | 3 semanas            |



## Experimentos, Resultados e Discuss√£o dos Resultados
Para a entrega parcial do projeto (E2), j√° foi feito um estudo de artigos na literatura no contexto do nosso projeto. Al√©m disso, seguindo o cronograma do projeto, tamb√©m foi finalizada a etapa de an√°lise da base de dados e a defini√ß√£o das etapas de pr√©-processamento, conforme j√° discutido brevemente na se√ß√£o sobre a base de dados. Mais ainda, tamb√©m foi realizada a implementa√ß√£o da arquitetura inicial das GANs escolhidas para o projeto, tomando como base o desenvolvimento em [[1]](#1), e iniciou-se a etapa de treinamento deste modelo.

Atualmente, estamos enfrentando dificuldades nesta etapa de treinamento, j√° que notamos que o discriminador estava ficando muito bom r√°pido demais, n√£o permitindo que o gerador conseguisse avan√ßar em seu aprendizado. Para solucionar este problema, tentaremos usar a estrat√©gia de atualizar a *loss* do gerador com mais frequ√™ncia do que a do discriminador (a priori, atualizaremos a loss do discriminador a cada 3 batches de atualiza√ß√£o da loss do gerador).

O resultado atual do nosso treinamento √© apresentado na figura abaixo. Nota-se que a sa√≠da do gerador ainda est√° distante do esperado e precisa ser aprimorada.

![Fatia original, fatia segmentada e sa√≠da da PulmoNet na terceira √©poca de treinamento.](figs/example_generated_epoch_3.png?raw=true)

*Figura 8: Fatia original, fatia segmentada e sa√≠da da PulmoNet na terceira √©poca de treinamento.*

Ademais outros problemas que estamos enfrentando durante a etapa do treinamento tratam do tamanho da nossa base de dados, que √© bem grande e resulta em um processamento demorado, e o uso de recursos em GPU.

## Conclus√£o
O projeto da rede PulmoNet busca a gera√ß√£o de fatias de CTs pulmonares a partir de m√°scaras bin√°rias, em duas dimens√µes, baseada em GANs. Esta rede utiliza uma arquitetura Pix2Pix para o gerador e uma PatchGAN para o discriminador. S√£o usados dados da base p√∫blica ATM'22, cujos dados correspondem a volumes pulmonares de tomografias e segmenta√ß√µes das vias a√©reas feitas por especialistas. Para a avalia√ß√£o da qualidade da rede, prop√µe-se m√©todos qualitativos, quantitativos e an√°lises de utilidade.

Seguindo o cronograma do projeto, as etapas at√© a entrega E2 foram cumpridas, de maneira que estamos atualmente na fase de treinamento do modelo e implementa√ß√£o dos m√©todos de avalia√ß√£o. No caso do treinamento, estamos enfrentando algumas dificuldades que est√£o afetando a qualidade das sa√≠das da rede, principalmente no quesito da velocidade de aprendizado do discriminador frente a do gerador.

Os pr√≥ximos passos do projeto tratam da finaliza√ß√£o do treinamento do modelo, an√°lise das m√©tricas de avalia√ß√£o e fine-tunning e aperfei√ßoamento do modelo. Caso tenhamos tempo dispon√≠vel, buscaremos a gera√ß√£o de volumes 3D de CTs pulmonares.

## Refer√™ncias Bibliogr√°ficas

<a id="1">[1]</a> : Jos√© Mendes et al., Lung CT image synthesis using GANs, Expert Systems with Applications, vol. 215, 2023, pp. 119350., https://www.sciencedirect.com/science/article/pii/S0957417422023685.

<a id="2">[2]</a> : Minghui Zhang et al., Multi-site, Multi-domain Airway Tree Modeling (ATM'22): A Public Benchmark for Pulmonary Airway Segmentation, https://arxiv.org/abs/2303.05745.

<a id="3">[3]</a> :  Jacopo Lenkowicz et al., A deep learning approach to generate synthetic CT in low field MR-guided radiotherapy for lung cases, Radiotherapy and Oncology, vol. 176, 2022, pp. 31-38, https://www.sciencedirect.com/science/article/pii/S0167814022042608.

<a id="4">[4]</a> : Swati P. Pawar and Sanjay N. Talbar, LungSeg-Net: Lung field segmentation using generative adversarial network, Biomedical Signal Processing and Control, vol. 64, 2021, 102296, https://www.sciencedirect.com/science/article/pii/S1746809420304158.

<a id="5">[5]</a> : Tekatli, Hil√¢l et al. ‚ÄúArtificial intelligence-assisted quantitative CT analysis of airway changes following SABR for central lung tumors.‚Äù Radiotherapy and oncology : journal of the European Society for Therapeutic Radiology and Oncology vol. 198 (2024): 110376. doi:10.1016/j.radonc.2024.110376, https://pubmed.ncbi.nlm.nih.gov/38857700/

<a id="6">[6]</a> : Zhang, Ling et al. ‚ÄúGeneralizing Deep Learning for Medical Image Segmentation to Unseen Domains via Deep Stacked Transformation.‚Äù IEEE transactions on medical imaging vol. 39,7 (2020): 2531-2540. doi:10.1109/TMI.2020.2973595, https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7393676/

<a id="7">[7]</a> : Hofmanninger, J., Prayer, F., Pan, J. et al. Automatic lung segmentation in routine imaging is primarily a data diversity problem, not a methodology problem. Eur Radiol Exp 4, 50 (2020). https://doi.org/10.1186/s41747-020-00173-2

<a id="8">[8]</a> : Isola, P., Zhu, J. Y., Zhou, T., & Efros, A. A. (2017). Image-to-image translation with conditional adversarial networks. In Proceedings - 30th IEEE conference on computer vision and pattern recognition, CVPR 2017. http://dx.doi.org/10.1109/CVPR.2017. 632, arXiv:1611.07004.

<a id="9">[9]</a> : Radford, A., Metz, L., and Chintala, S., ‚ÄúUnsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks‚Äù, <i>arXiv e-prints</i>, Art. no. arXiv:1511.06434, 2015. doi:10.48550/arXiv.1511.06434.

Documento com as refer√™ncias extras identificadas: https://docs.google.com/document/d/1uatPj6byVIEVrvMuvbII6J6-5usOjf8RLrSxLHJ8u58/edit?usp=sharing
