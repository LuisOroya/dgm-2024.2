# `PulmoNet: Rede Neuronal Generativa para Imagens Tomogr√°ficas Pulmonares`
# `PulmoNet: Generative Neuronal Network for Pulmonary Tomographic Images`

## Apresenta√ß√£o

O presente projeto foi originado no contexto das atividades da disciplina de p√≥s-gradua√ß√£o *IA376N - IA generativa: de modelos a aplica√ß√µes multimodais*, 
oferecida no segundo semestre de 2024, na Unicamp, sob supervis√£o da Profa. Dra. Paula Dornhofer Paro Costa, do Departamento de Engenharia de Computa√ß√£o e Automa√ß√£o (DCA) da Faculdade de Engenharia El√©trica e de Computa√ß√£o (FEEC).

 |Nome  | RA | Especializa√ß√£o|
 |--|--|--|
 | Arthur Matheus Do Nascimento | 290906 | Eng. El√©trica |
 | J√∫lia Castro de Paula | 219193 | Eng. El√©trica |
 | Let√≠cia Levin Diniz | 201438  | Eng. El√©trica |

## Tabela de Conte√∫dos

1. [Resumo](#resumo-abstract)
2. [Links Importantes](#links-importantes)
3. [Descri√ß√£o do Problema / Motiva√ß√£o](#descri√ß√£o-do-problemamotiva√ß√£o)
4. [Objetivo](#objetivo)
5. [Metodologia](#metodologia)
    1. [Materiais de Refer√™ncia](#materiais-de-refer√™ncia)
    2. [Modelo Proposto](#modelo-proposto)
    3. [Bases de Dados e Evolu√ß√£o](#bases-de-dados-e-evolu√ß√£o)
    4. [Workflow](#workflow)
    5. [Ferramentas Relevantes](#ferramentas-relevantes)
    6. [M√©tricas de Avalia√ß√£o](#m√©tricas-de-avalia√ß√£o)
        1. [An√°lise Qualitativa](#an√°lise-qualitativa)
        2. [An√°lise Quantitativa](#an√°lise-quantitativa)
        3. [An√°lise de Utilidade](#an√°lise-de-utilidade)
    7. [Cronograma](#cronograma)
    8. [Ambiente Computacional](#ambiente-computacional)
6. [Experimentos, Resultados e Discuss√£o dos Resultados](#experimentos-resultados-e-discuss√£o-dos-resultados)
7. [Conclus√£o](#conclus√£o)
    1. [Pr√≥ximos Passos](#pr√≥ximos-passos)
8. [Refer√™ncias Bibliogr√°ficas](#refer√™ncias-bibliogr√°ficas)

**ANEXOS**:
1. [Varredura dos par√¢metros da GAN para 10 mil dados]()
2. [Testes adicionais com outras arquiteturas]()
3. [Como rodar os modelos](#how-to-run)

## Links Importantes
Links para apresenta√ß√µes de slides e v√≠deos para entregas E1, E2 e E3 para a disciplina:

[Link para o v√≠deo de apresenta√ß√£o E1](https://drive.google.com/file/d/1TlpQOlCh_lAI0-jPPMPWOzGZ_werCo3d/view?usp=sharing)

[Link para a apresenta√ß√£o de slides E1](https://docs.google.com/presentation/d/1b8W0Cw1eiTbWlJ0CJJ8eMRA4zyu2iLhYvggi55-mOb0/edit?usp=sharing)

[Link para a apresenta√ß√£o de slides E2](https://docs.google.com/presentation/d/1QH5_WpeTp7kQPSVB78ukK7msn-Tx09pZoM_3dWmeqC4/edit?usp=sharing)

> TODO: link E3

## Resumo (Abstract)

> TODO: Update

As tomografias computadorizadas (CT) pulmonares e a segmenta√ß√£o das vias a√©reas s√£o essenciais para o diagn√≥stico preciso de doen√ßas pulmonares. Prop√µe-se a PulmoNet, uma rede para s√≠ntese de imagens 2D de CTs pulmonares, visando apoiar redes de segmenta√ß√£o e gerar dados sint√©ticos para bases de dados de outras redes neurais, como classificadores de tumores. Utilizando a base ATM'22, implementa-se uma arquitetura GAN com gerador Pix2Pix e discriminador PatchGAN, que preencher√° m√°scaras bin√°rias do pulm√£o com vias a√©reas. Avalia-se a rede qualitativamente, quantitativamente (m√©tricas FID e SSIM) e em utilidade. Resultados parciais indicam problemas no treinamento devido √† velocidade de aprendizado do discriminador.

## Descri√ß√£o do Problema/Motiva√ß√£o
As tomografias computadorizadas (CT) pulmonares, juntamente com a segmenta√ß√£o das vias a√©reas, desempenham um papel crucial no diagn√≥stico preciso de doen√ßas pulmonares. Ao gerar imagens detalhadas da regi√£o tor√°cica, a tomografia permite que m√©dicos mapeiem a anatomia das vias a√©reas antes de procedimentos cir√∫rgicos, avaliando a extens√£o de les√µes e facilitando o acompanhamento da progress√£o de doen√ßas respirat√≥rias [[2]](#2). Al√©m disso, a CT √© fundamental para monitorar a efic√°cia de tratamentos e detectar seus poss√≠veis efeitos colaterais [[5]](#5).

A complexidade e diversidade do corpo humano, bem como o custo e acesso a CT, limitam a obten√ß√£o de grandes volumes de dados que sejam representativos das diversas condi√ß√µes anat√≥micas. Essa escassez de dados limita a performance de modelos de aprendizado de m√°quina, como redes neurais, que utilizam de tais dados para promover ferramentas que auxiliem a equipe m√©dica. A limita√ß√£o de tais modelos pode levar a diagn√≥sticos imprecisos, e comprometer a qualidade do atendimento a pacientes [[6]](#6). Com as redes generativas √© poss√≠vel criar dados de forma a compensar essa escassez, potencialmente aprimorando a performance de modelos treinados com o suporte desses dados sint√©ticos.

## Objetivo
Este projeto visa gerar imagens sint√©ticas de tomografia computadorizada (CT) da regi√£o tor√°cica. A priori, o modelo generativo proposto ter√° como sa√≠da imagens em duas dimens√µes (2D) de CT da regi√£o do t√≥rax. Busca-se um grau de realismo suficiente para auxiliar redes de segmenta√ß√£o de vias a√©reas. 
Al√©m disso, este trabalho tamb√©m serve como uma primeira etapa de um projeto maior e mais ambicioso, no qual buscar-se-√° a gera√ß√£o de volumes (3D) de tomografias pulmonares, uma combina√ß√£o de imagens que juntas formam o equivalente a um exame real.

## Metodologia
### Materiais de Refer√™ncia
Este projeto usar√° como inspira√ß√£o inicial o trabalho desenvolvido em [[1]](#1), o qual prop√µe duas arquiteturas baseadas em GANs para a s√≠ntese de imagens CT pulmonares a partir de m√°scaras bin√°rias que segmentam a regi√£o pulmonar. Das arquiteturas propostas, inspirar-se-√° na arquitetura Pix2Pix, na qual o gerador √© composto de um encoder que aumenta a profundidade da imagem enquanto diminui suas dimens√µes, seguido de um decoder que realiza o processo oposto. Tal arquitetura tamb√©m utiliza conex√µes residuais. Na arquitetura Pix2Pix, o discriminador √© composto por cinco camadas convolucionais, onde as quatro primeiras s√£o seguidas por uma camada de ativa√ß√£o *LeakyReLu*, enquanto a √∫ltima √© seguida de uma fun√ß√£o *sigmoide*. 

Al√©m do artigo [[1]](#1), tamb√©m ser√£o considerados os trabalhos realizados em [[3]](#3) e [[4]](#4). No primeiro, desenvolveu-se uma GAN condicional para a gera√ß√£o de imagens CT pulmonares a partir de imagens de resson√¢ncia magn√©tica. J√° no segundo, utiliza-se um modelo baseado em GAN para a segmenta√ß√£o do pulm√£o em imagens CT que cont√©m anomalias no tecido pulmonar. Apesar dos objetivos de tais trabalhos n√£o serem os mesmos objetivos propostos para o presente projeto, eles servir√£o de apoio para proposi√ß√£o de modifica√ß√µes na arquitetura, estrat√©gias de treino e de valida√ß√£o de resultados.   

### Modelo Proposto

> TODO: Atualizar arquiteturas + descrever melhor a loss

Conforme j√° discutido na se√ß√£o anterior, ap√≥s um estudo de outros artigos correlatos ao nosso projeto, verificamos que a estrat√©gia predominante para a s√≠ntese de CTs pulmonares e convers√£o imagem para imagem corresponde a aplica√ß√£o de GANs (redes advers√°rias generativas).
Em uma GAN, temos uma rede neural "geradora", respons√°vel por sintetizar as distribui√ß√µes de entrada e retornar sa√≠das similares aos dados reais, e uma rede neural "discriminadora", que deve ser capaz de classificar corretamente suas entradas como "reais" ou "falsas". Com isso, uma boa rede generativa deve ser capaz de enganar o discriminador, ao passo que um bom discriminador deve identificar corretamente os dados sint√©ticos em meio aos dados reais.

No caso espec√≠fico da nossa aplica√ß√£o, utilizaremos como refer√™ncia principal as arquiteturas propostas em [[1]](#1). Neste trabalho, uma rede Pix2Pix √© utilizada pelo gerador, recebendo uma m√°scara bin√°ria com o formato de um pulm√£o em um CT e retornando esta imagem 2D preenchida com as vias a√©ras de um pulm√£o. J√° a rede discriminadora segue a arquitetura 30 √ó 30 PatchGAN. Ambas estas estruturas foram inicialmente recomendadas por [[8]](#8).
As duas imagens abaixo ilustram as arquiteturas do gerador e discriminador, respectivamente.

![Arquitetura Pix2Pix proposta para gerador.](figs/arquitetura_gen.png?raw=true)

*Figura 1: Arquitetura Pix2Pix proposta para gerador.*

![Arquitetura PatchGAN proposta para discriminador.](figs/arquitetura_disc.png?raw=true)

*Figura 2: Arquitetura PatchGAN proposta para discriminador.*

A fun√ß√£o de *loss* aplica um crit√©rio similar √† *Binary Cross Entropy*, com regulariza√ß√£o por MAE (*Mean Absolute Error*), conforme a seguinte a equa√ß√£o matem√°tica:

$$arg\ min_{ùê∫}\ max_{ùê∑}\ E_{ùë•,ùë¶}[log ùê∑(ùë•, ùë¶)] + E_{ùë•,ùëß}[log(1 ‚àí ùê∑(ùë•, ùê∫(ùë•, ùëß)))] + ùúÜE_{ùë•,ùë¶,ùëß}[‚Äñùë¶ ‚àí ùê∫(ùë•, ùëß)‚Äñ_{1}]$$

> Idealmente, deseja-se que a fun√ß√£o de *loss* do gerador e a do discriminador encontrem um equil√≠brio em torno de 0.5 (refer√™ncia Goodfellow)

### Bases de Dados e Evolu√ß√£o
Apesar de inspirar-se no artigo [[1]](#1), o desenvolvimento deste projeto utilizar√° a base de dados ATM'22, cuja descri√ß√£o est√° na tabela abaixo. Tal base de dados n√£o foi usada no desenvolvimento do projeto em [[1]](#1), mas foi escolhida no presente projeto devido a sua amplitude, a presen√ßa de dados volum√©tricos e em raz√£o das imagens possu√≠rem a delimita√ß√£o das vias a√©reas obtidas atrav√©s de especialistas. Os volumes da base ATM'22 foram adquiridos em diferentes cl√≠nicas e considerando diferentes contextos cl√≠nicos. Constru√≠da para a realiza√ß√£o de um desafio de segmenta√ß√£o autom√°tica de vias a√©ria utilizando IA, a base de dados est√° dividida em 300 volumes para treino, 50 para valida√ß√£o e 150 para teste.

|Base de Dados | Endere√ßo na Web | Resumo descritivo|
|----- | ----- | -----|
|ATM'22 | https://zenodo.org/records/6590774 e https://zenodo.org/records/6590775  | Esta base cont√©m 500 volumes CTs pulmonares, nos quais as vias a√©reas est√£o completamente anotadas, i.e., delimitadas. Tais volumes ser√£o fatiados em imagens 2-D, segmentados e transformados. Esta base de dados foi utilizada para um desafio de segmenta√ß√£o [[2]](#2).|

Os dados desta base s√£o arquivos com extens√£o `*.nii.gz`, em um formato caracter√≠stico de imagens m√©dicas, e cont√™m todo o volume pulmonar obtido durante um exame de tomografia. Cada arquivo com um volume pulmonar √© acompanhado por um outro arquivo de mesma extens√£o contendo as anota√ß√µes feitas por especialistas.
Tais dados s√£o lidos com aux√≠lio da biblioteca `SimpleITK`, conforme feito pelas classes em `datasets.py` neste reposit√≥rio.

Dado que este trabalho centrar√°-se na gera√ß√£o de imagens sint√©ticas em duas dimens√µes de CTs pulmonares, estes volumes pulmonares ser√£o fatiados no eixo transversal, assim como ilustrado na imagem abaixo. Como resultado, fatiaremos os 500 volumes pulmores em uma quantidade muito maior de imagens 2D, aumentando o tamanho dos conjuntos de dados dispon√≠veis para treinamento, valida√ß√£o e testes.

![Exemplo de fatia de CT pulmonar obtida a partir da base de dados ATM'22.](figs/dataset_exemplo_fatia.png?raw=true)

*Figura 3: Exemplo de fatia de CT pulmonar obtida a partir da base de dados ATM'22.*

A quantia exata de dados que ser√£o utilizados depende da configura√ß√£o da fatia obtida. Isto √©, n√£o ser√£o utilizadas todas as fatias do volume pulmonar, mas sim apenas as imagens que apresentarem o pulm√£o completo e cercado por tecidos. A partir desta condi√ß√£o, as fatias ser√£o selecionadas e utilizadas como entrada da rede geradora. Ressalta-se que esta sele√ß√£o √© necess√°ria, uma vez que √© uma restri√ß√£o da biblioteca em Python `lungmask` [[7]](#7), utilizada para segmenta√ß√£o autom√°tica de CTs pulmonares.
Tamb√©m √© pertinente destacar que esta segmenta√ß√£o √© uma etapa essencial do workflow, posto que os dados de entrada da rede geradora da GAN ser√£o m√°scaras pulmonares, tal como feito em [[1]](#1).

O gr√°fico abaixo ilustra o histograma da base de dados ap√≥s a sele√ß√£o das fatias. Para a constru√ß√£o deste histograma, calculou-se a quantidade de pixels de cada imagem que descrevem a regi√£o pulmonar (a parte em branco ap√≥s a m√°scara de segmenta√ß√£o). Nota-se que temos muitas imagens com at√© 2 mil pixels para compor o pulm√£o, depois temos uma queda nesta quantidade de imagens at√© algo em torno de 20 mil pixels, seguido por uma nova regi√£o de m√°ximo - temos a maior concentra√ß√£o das imagens usadas pela rede generativa com o pulm√£o ocupando entre 30 e 40 mil pixels. Depois disso, a quantidade exemplares com mais pixels vai diminuindo gradualmente at√© pouco mais de 100 mil pixels.
Um ponto importante a ser mencionado √© que apesar do histograma come√ßar em zero, a menor quantia de pixels no conjunto ap√≥s segmenta√ß√£o √© de 100 pixels. Ademais, dado que s√£o imagens com dimens√£o 512 x 512 e, portanto, t√™m mais de 260 mil pixels, as imagens com a maior quantidade de pixels para a regi√£o do pulm√£o n√£o ocupam nem metade de todos os pixels dispon√≠veis.

![Histrograma da quantidade de pixels das fatias selcionadas ap√≥s segmenta√ß√£o das CTS pulmonares da base de dados ATM'22.](figs/histograma_fatias.png?raw=true)

*Figura 4: Histrograma da quantidade de pixels das fatias selcionadas ap√≥s segmenta√ß√£o das CTS pulmonares da base de dados ATM'22.*

A figura abaixo apresenta exemplos de fatias em regi√µes distintas deste histograma para podermos visualizar a variabilidade dos dados de entrada da rede.
Nota-se que as fatias com menos de 10 mil pixels para descrever o pulm√£o praticamente n√£o t√™m regi√£o suficiente para ser preenchida com vias a√©reas, ao passo que as imagens com mais pixels para a regi√£o do pulm√£o s√£o aquelas mais pr√≥ximas de uma fatia no meio do pulm√£o, exibindo a maior √°rea util deste √≥rg√£o.
Com base nestas an√°lises, descarta-se as imagens com menos 25 mil pixels para o pulm√£o, realizando uma segunda etapa de filtragem da base de dados.

![Exemplos de fatias das CTS pulmonares da base de dados ATM'22 segmentadas.](figs/exemplos_pixels.png?raw=true)

*Figura 5: Exemplos de fatias das CTS pulmonares da base de dados ATM'22 segmentadas.*

Deste modo, ao selecionar apenas as imagens com mais de 25 mil pixels com a regi√£o do pulm√£o, conseguimos construir uma base de dados com pouco mais de 90 mil figuras. Tais imagens devem, ent√£o, ser divididas em conjuntos de treinamento, valida√ß√£o e testes.
Para facilitar o c√°lculo desta separa√ß√£o, opta-se por fixar a base de dados em 90 mil amostras.

Considerando que a parte de testes do modelo envolve uma etapa de teste de utilidade, em que uma rede de segmenta√ß√£o ser√° treinada e avaliada, o tamanho do conjunto de testes total n√£o pode ser pequeno demais.
Al√©m disso, para uma compara√ß√£o mais justa com o nosso artigo de refer√™ncia, optamos por utilizar a mesma quantidade de dados de teste para c√°lculo das demais m√©tricas sobre a qualidade da GAN obtida (FID e SSIM), de maneira a fixar 7 mil dados para c√°lculo destas m√©tricas no conjunto de testes.
Em fun√ß√£o disso, levando em considera√ß√£o os testes qualitativos, quantitativos e de utilidade, separa-se cerca de um quarto de toda a base de dados para todos os testes.

Ademais, para evitar um conjunto de valida√ß√£o da GAN maior do que o conjunto para obten√ß√£o das m√©tricas do modelo (FID e SSIM), opta-se por manter a mesma quantidade de dados para esta tarefa, isto √©, 7 mil dados.
Com isso, em uma vis√£o geral, separa-se dois ter√ßos (cerca de 66,7%) da base de dados completa para o treinamento da GAN, 7,8% para a valida√ß√£o da GAN e 25,6% para todos os testes (inclu√≠ndo a an√°lise qualitativa, an√°lise quantitativa e o teste de utilidade).
Uma representa√ß√£o gr√°fica desta separa√ß√£o est√° ilustrada na figura abaixo.

![Separa√ß√£o da base de dados completa em conjuntos de treinamento, valida√ß√£o e testes. Vis√£o geral desta separa√ß√£o, em porcentagem.](figs/Dados_porcentagem.png?raw=true)

*Figura 6: Separa√ß√£o da base de dados completa em conjuntos de treinamento, valida√ß√£o e testes. Vis√£o geral desta separa√ß√£o, em pocentagem.*

Desconsiderando os testes de utilidade e focando apenas nos testes qualitativos e quantitativos, temos 60 mil dados para treinamento da GAN, 7 mil para valida√ß√£o e 7 mil para testes. Isso representa um propor√ß√£o pr√≥xima a 80-10-10, uma das mais cl√°ssicas na literatura para treinamento de redes neurais.
A figura abaixo ilustra graficamente esta propor√ß√£o de dados.

![Separa√ß√£o da base de dados em conjuntos de treinamento, valida√ß√£o e testes, considerando apenas os testes qualitativos e quantitativos para avalia√ß√£o da GAN.](figs/Dados_GAN.png?raw=true)

*Figura 7: Separa√ß√£o da base de dados em conjuntos de treinamento, valida√ß√£o e testes, considerando apenas os testes qualitativos e quantitativos para avalia√ß√£o da GAN.*

Por sua vez, considerando apenas o teste de utilidade, ter√≠amos 16 mil dados dispon√≠veis para o treinamento, valida√ß√£o e teste destes modelos de segmenta√ß√£o de vias a√©reas (23 mil dados do conjuto de testes total menos 7 mil dados do conjunto de testes qualitativos e quantitativos da GAN).
Todavia, considerando que o conjunto de testes da GAN para as outras m√©tricas n√£o tem rela√ß√£o com os dados da rede de segmenta√ß√£o, podemos reaproveitar este conjunto para obten√ß√£o das m√©tricas do teste de utilidade.
Com isso, restam 16 mil dados para serem divididos em conjuntos de treinamento e valida√ß√£o das redes de segmenta√ß√£o. Opta-se por uma quantidade maior de dados de treinamento, considerando o tamanho deste conjunto total, de maneira a selecionar 14 mil dados para treinamento e 2 mil para valida√ß√£o.
Com isso, para a rede de segmenta√ß√£o, ter√≠amos uma propor√ß√£o de conjuntos pr√≥xima a 60-10-30, o que tamb√©m √© bem comum na literatura e √© a propor√ß√£o utilizada no desafio de segmenta√ß√£o da base ATM'22 [[2]](#2).
A figura abaixo ilustra a divis√£o deste conjunto.

![Separa√ß√£o da base de dados em conjuntos de treinamento, valida√ß√£o e testes, considerando apenas o teste de utilidade (rede neural para segmenta√ß√£o das vias a√©reas pulmonares).](figs/Dados_seg.png?raw=true)

*Figura 8: Separa√ß√£o da base de dados em conjuntos de treinamento, valida√ß√£o e testes, considerando apenas o teste de utilidade (rede neural para segmenta√ß√£o das vias a√©reas pulmonares).*

Em suma, a separa√ß√£o da base de dados completa em conjuntos de treinamento para GAN, valida√ß√£o da GAN, treinamento da rede de segmenta√ß√£o, valida√ß√£o da rede de segmenta√ß√£o e testes da GAN e da rede de segmenta√ß√£o est√° ilustrada na figura abaixo. Nota-se que, devido ao reaproveitamento do conjunto de testes entre a GAN e a rede de segmenta√ß√£o, temos ao final cinco (5) conjuntos na sa√≠da desta etapa.

![Separa√ß√£o da base de dados completa em conjuntos de treinamento, valida√ß√£o e testes. Vis√£o geral desta separa√ß√£o.](figs/Dados_visao_geral.png?raw=true)

*Figura 9: Separa√ß√£o da base de dados completa em conjuntos de treinamento, valida√ß√£o e testes. Vis√£o geral desta separa√ß√£o.*

Por fim, ressalta-se que al√©m da segmenta√ß√£o dos dados e sele√ß√£o das fatias, a base de dados tamb√©m passa pelas etapas de normaliza√ß√£o e de transforma√ß√£o para `numpy arrays`, antes de ser utilizada pelas GANs implementadas neste projeto.
A figura abaixo resume esta etapa de tratamento dos dados por completo.

![Fluxograma para processamento da base de dados.](figs/Fluxo_proc_dados.png?raw=true)

*Figura 10: Fluxograma para processamento da base de dados.*

### Workflow

> TODO: Incluir mais detalhes da metodologia

Em uma perspectiva geral do projeto, a metodologia se divide em tr√™s grandes est√°gios:
1. Prepara√ß√£o da base de dados;
2. Treinamento e fine-tunning de modelos de s√≠ntese;
3. Avalia√ß√£o dos modelos gerados.

No que diz respeito √† prepara√ß√£o da base de dados, aplica-se o fluxo descrito na Figura 10, da se√ß√£o anterior, na qual os dados s√£o obtidos de uma fonte p√∫blica, processados e separados em conjuntos de treinamento, valida√ß√£o cruzada e testes. A sa√≠da desta etapa s√£o 90 mil trios (fatia da CT pulmonar, segmenta√ß√£o feita por especialistas e m√°scara bin√°ria da regi√£o do pulm√£o), com dimens√£o 1 x 512 x 512 cada.

Quanto a segunda etapa, implementa-se a arquitetura de uma GAN, descrita na se√ß√£o [Modelo Proposto](#modelo-proposto), que foi concebida tomando como base o artigo [[1]](#1). Sob esta arquitetura, realiza-se uma busca pelos par√¢metros √≥timos de treinamento da rede conforme a tabela abaixo, a fim de encontrar a melhor combina√ß√£o para gerar imagens sint√©ticas de CTs pulmonares mais realistas.
Esta varredura inicial √© feita com apenas 10 mil dados e analisada no conjunto de testes de maneira qualitativa (an√°lise subjetiva dos alunos quanto aos resultados) e quantitativa (c√°lculo das m√©tricas FID e SSIM).
A partir desta an√°lise inicial, seleciona-se tr√™s modelos para prosseguir com o treinamento com todos os dados dispon√≠veis.

|Par√¢metros | Possibilidades |
|----- | ----- |
|Passos Disc | 1 a 10 |
|Passos Gen | 1 a 10 |
|Tipo de ru√≠do | [Uniforme, Gaussiano] |
|Localiza√ß√£o do ru√≠do | Na imagem completa ou apenas na regi√£o do pulm√£o|
|Regulariza√ß√£o | [0, 10] |
|Beta |Entre 1989 e 2000 |
|blabla | blabla |

Dadas as restri√ß√µes de tempo e capacidade computacional, n√£o foram testadas todas as combina√ß√µes de par√¢metros da tabela acima. Com apoio da ferramenta Weights & Biases, combinou-se aleatoriamente estes par√¢metros em quinze modelos, descritos na tabela abaixo.
A configura√ß√£o destes par√¢metros √© feita em um arquivo YAML.

[jogar para resultados -----------------]

|Modelo |	Rela√ß√£o Passos (Disc/Gen) |	Ru√≠do |	Ru√≠do s√≥ no pulm√£o|	Intensidade	|M√©dia Ru√≠do	|Desvio Ru√≠do	|Criterion	|Regularizador	|N√≠vel Regulariza√ß√£o	|Learning Rate	|Beta|
| ----- | ----- | -----   | ----- | -----       | -----         | -----         |   -----  | ----- | -----| -----   |   -----       |
|Sweep10|	4/2	|Gaussiano|	Falso |	0,3157719473|	0,7469069764|	0,1784581512|	BCELoss|	MSE|	8|	3,11E-04|	0,4597517629|
|Sweep205|	3/1	|Gaussiano|	Verdadeiro|	0,5566831094|	0,5120044953|	0,3903814624|	MSELoss|	MAE|	10|	2,85E-04|	0,7555202559|
|Sweep412|	1/1| Gaussiano|	Falso| 0,757255249|	0,5250495573|	0,4755411392|	MSELoss|	MAE|	4	|1,70E-04	|0,8811316699|
|Sweep64	|1/2	|Gaussiano	|Verdadeiro	|0,81851453	|0,5597838196	|0,2229110595	|MSELoss	|MAE	|3	|3,75E-04	|0,8659691523|
|Sweep123	|2/1	|Gaussiano	|Verdadeiro	|0,3320755603	|0,652635058	|0,3347731658	|MSELoss	|MAE	|4	|1,55E-04	|0,6252443893|
|Sweep284	|1/2	|Gaussiano	|Verdadeiro	|0,4882098594	|0,872090533	|0,4466720449	|MSELoss	|MSE	|4	|2,24E-04	|0,6781061686|
|Sweep394	|2/1	|Gaussiano	|Falso	|0,3715918515	|0,6996284578	|0,2871496533	|BCELoss	|MAE	|1	|3,40E-04	|0,4792751887|
|Sweep497	|1/1	|Gaussiano	|Verdadeiro	|0,3039449554	|0,8749711247	|0,2897599163	|MSELoss	|MSE	|15	|1,32E-04	|0,840671948|
|Sweep522	|4/2	|Gaussiano	|Falso	|0,8766142328	|0,6935412609	|0,3790460335	|MSELoss	|MSE_mask	|13	|3,40E-04	|0,5728743005|
|Sweep71	|2/1	|Gaussiano	|Verdadeiro	|0,8172635438	|0,548984276	|0,3265456309	|BCELoss	|MSE_mask	|1	|2,82E-04	|0,52631016|
|Sweep185	|4/1	|Uniforme	|Verdadeiro	|0,3563791549|	0,5899638112|	0,2158650277|	MSELoss|	MAE_mask|	5|	2,82E-04|	0,4240341338|
|Sweep186	|2/1	|Uniforme	|Verdadeiro	|0,9795390854|	0,5310213915	|0,2623582226	|BCELoss	|MAE_mask	|4	|1,87E-04	|0,6069949071|
|Sweep256	|1/2	|Gaussiano	|Verdadeiro	|0,3085178607	|0,6810390549	|0,1347611367	|MSELoss	|MAE_mask	|8	|3,16E-04	|0,4703302188|
|Sweeo279	|4/2	|Gaussiano	|Falso	|0,6821396703	|0,9681958035	|0,1024100341	|MSELoss	|MAE_mask	|15	|2,58E-04	|0,6470046351|
|Sweep464	|2/2	|Gaussiano	|Verdadeiro	|0,9864110063	|0,9929413808	|0,1007233152	|MSELoss	|MSE_mask	|1	|2,91E-04	|0,4393293661|

Ap√≥s esta etapa, passa-se os tr√™s melhores modelos para a etapa de avalia√ß√£o de desempenho e qualidade dos resultados. Gera-se imagens sint√©ticas a partir de m√°scaras bin√°rias de CTs pulmonares com ru√≠do e realiza-se tr√™s testes: qualitativo, quantitativo e de utilidade. Tais testes ser√£o descritos em mais detalhes na se√ß√£o [M√©tricas de Avalia√ß√£o](#m√©tricas-de-avalia√ß√£o).

Um ponto importante a ser destacado √© a diferen√ßa do tipo de ru√≠do aplicado na m√°scara de entrada do gerador. Como √© poss√≠vel observar nas tabelas acima, duas distribui√ß√µes foram testadas: uniforme e gaussiana. xxxxxx

Em suma, o fluxo de trabalho proposto por este projeto, ilustrado na figura a seguir, inicia-se com a obten√ß√£o da base de dados ATM'22 e seu devido tratamento, conforme detalhado na se√ß√£o anterior.
Utilizando estes dados, alimenta-se a rede generativa com as fatias segmentadas (m√°scaras bin√°rias). J√° a rede discriminadora recebe os dados reais (sem segmenta√ß√£o) e os dados sint√©ticos, devendo classificar cada um como "real" ou "falso".
Ap√≥s o treinamento, avalia-se os dados sint√©ticos a partir de tr√™s perspectivas: an√°lise qualitativa, an√°lise quantitativa e an√°lise de utilidade, as quais ser√£o descritas em detalhes nas pr√≥ximas se√ß√µes deste relat√≥rio.

![Fluxo para treinamento da PulmoNet.](figs/workflow_completo.png?raw=true)

*Figura 11: Fluxo para treinamento da PulmoNet.*

Destaca-se que, em opera√ß√£o (ap√≥s a fase treinamento), espera-se que o modelo receba m√°scaras bin√°rias com o formato do pulm√£o somadas a um ru√≠do, retonando o preenchimento da √°rea interna do pulm√£o.
Uma mesma m√°scara bin√°ria poder√° gerar imagens sint√©ticas distintas, devido ao ru√≠do aleat√≥rio adicionado na entrada do modelo.
Os dados sint√©ticos dever√£o ser bons o suficiente para ajudarem no treinamento de modelo de segmenta√ß√£o das vias a√©reas e potencialmente substituir o uso de dados reais, para a preserva√ß√£o da privacidade dos pacientes.

### Ferramentas Relevantes
A ferramenta escolhida para o desenvolvimento da arquitetura dos modelos e de treinamento √© o **PyTorch**, em fun√ß√£o de sua relev√¢ncia na √°rea e familiaridade por parte dos integrantes do grupo.
Ademais, para o desenvolvimento inicial e colaborativo dos modelos entre os estudantes, opta-se pela ferramenta de programa√ß√£o **Google Collaboratory**.
J√° para o versionamento dos modelos e para ajustar seus hiperpar√¢metros, decidiu-se pela ferramenta **Weights & Biases (Wandb AI)** dentre as op√ß√µes dispon√≠veis no mercado. E, al√©m disso, a ferramenta do **GitHub** tamb√©m auxiliar√° no versionamento dos algoritmos desenvolvidos.

### M√©tricas de Avalia√ß√£o
Para avaliar a qualidade dos resultados obtidos com o modelo de s√≠ntese, prop√µe-se tr√™s tipos de avalia√ß√£o: an√°lise qualitativa, an√°lise quantitativa e an√°lise de utilidade.

#### An√°lise Qualitativa
Esta estrat√©gia ser√° utilizada apenas nas etapas iniciais do desenvolvimento do projeto, na qual os pr√≥prios estudantes ir√£o observar os resultados sint√©ticos, sejam eles imagens e/ou  volumes, e comparar√£o com os dados reais esperados. Com isto, faz-se uma avalia√ß√£o se a imagem gerada estaria muito distante de uma CT pulmonar ou se o modelo j√° estaria se encaminhando para bons resultados. Ap√≥s esta etapa, as avalia√ß√µes do modelo ser√£o feitas por meio das an√°lises quantitativa e de utiliddade.

#### An√°lise Quantitativa
A an√°lise quantitativa trata de uma avalia√ß√£o sobre as imagens a partir dos m√©todos **Fr√©chet Inception Distance (FID)** e **Structural Similarity Index (SSIM)**, os quais s√£o utilizados para avalia√ß√£o de qualidade das imagens sint√©ticas e de similaridade com dados reais. Ambas estrat√©gias foram utilizadas pelos pesquisadores do artigo [[1]](#1), o que permite uma avalia√ß√£o dos nossos resultados frente a esta outra pesquisa.

Entrando em mais detalhes, a m√©trica FID avalia o desempenho da rede generativa e ser√° calculada utilizando uma rede neural pr√©-treinada *InceptionV3*, que extrair√° *features* das fatias pulmonares geradas e das fatias originais. Com isso, as distribui√ß√µes dos dados sint√©ticos e dos dados reais, obtidas pelo encoder desta rede, s√£o usadas para calcular a FID e, assim, avaliar a qualidade da imagem gerada.
A express√£o matem√°tica que descreve o c√°lculo da FID entre duas distribui√ß√µes gaussianas criadas pelas *features* da √∫ltima camada de *pooling* do modelo *Inception-v3* √© dada por:

$$FID = ‚Äñùúá_{ùëü} ‚àí ùúá_{ùëî}‚Äñ^{2} + Tr(\sum_{ùëü} + \sum_{ùëî} ‚àí 2(\sum_{ùëü}\sum_{ùëî})^{1‚àï2})$$

onde $ùúá_{ùëü}$ e $ùúá_{ùëî}$ s√£o as m√©dias entre as imagens reais e sint√©ticas, e $\sum_{ùëü},\ \sum_{ùëî}$ s√£o as matrizes de convari√¢ncia para os vetores de *features* dos dados reais e gerados, respectivamente.
Quanto menor for o FID, maior a qualidade da imagem gerada.

Por sua vez, a m√©trica SSIM compara a imagem gerada com seu respectivo *ground-truth* com base em tr√™s caracter√≠sticas: lumin√¢ncia, distor√ß√£o de contraste e perda de correla√ß√£o estrutural.
As express√µes matem√°ticas usadas para o c√°lculo desta m√©trica s√£o:

$$SSIM(ùë•, ùë¶) = l(ùë•, ùë¶) \times ùëê(ùë•, ùë¶) \times ùë†(ùë•, ùë¶)$$

$$
l(x, y) = \frac{2\mu_{x}\mu_{y} + C_{1}}{\mu_{x}^{2} + \mu_{y}^{2} + C_{1}}
$$

$$
c(x, y) = \frac{2\sigma_{x}\sigma_{y} + C_{2}}{\sigma_{x}^{2} + \sigma_{y}^{2} + C_{2}}
$$

$$ùë†(ùë•, ùë¶) = \frac{ùúé_{ùë•ùë¶} + ùê∂_{3}}{ùúé_{ùë•}ùúé_{ùë¶} + ùê∂_{3}}$$

onde $ùúá_{ùë•}$, $ùúá_{ùë¶}$, $ùúé_{ùë•}$, $ùúé_{ùë¶}$, e $ùúé_{ùë•ùë¶}$ s√£o as m√©dias locais, vari√¢ncias e covari√¢ncias cruzadas para as imagens ùë•, ùë¶, respectivamente. $ùê∂_{1}$, $ùê∂_{2}$ $ùê∂_{3}$ s√£o constantes.

No caso do c√°lculo do SSIM, como o foco do projeto est√° associado com uma boa gera√ß√£o de vias a√©reas pulmonares, esta m√©trica √© calculada considerando tanto a sa√≠da completa (imagem 512 x 512) quanto apenas a regi√£o central (imagem 256 x 256).

#### An√°lise de Utilidade
Dado que o objetivo do projeto √© gerar imagens sint√©ticas (2D) de CTs pulmonares realistas, avalia-se nesta etapa duas perspectivas. A primeira delas trata da segmenta√ß√£o das fatias sint√©ticas por meio da biblioteca *lungmask* e compara√ß√£o desta sa√≠da com a m√°scara bin√°ria original que gerou esta imagem sint√©tica. Isto √© feito para avaliar se o gerador conseguiu manter o formato do pulm√£o original ou algo pr√≥ximo a isso. Utiliza-se o SSIM para compara√ß√£o destas duas fatias pulmonares segmentadas.

J√° a segunda perspectiva trata da utilidade do gerador, em termos de **feature extraction**. Isto √©, tomando como inspira√ß√£o a abordagem explorada em [[9]](#9), implementaremos uma U-Net, com a mesma estrutura da rede geradora Pix2Pix da PulmoNet, para realizar a segmenta√ß√£o das vias a√©reas e compararemos o desempenho desta U-Net com uma outra rede que utiliza as *features* extra√≠das pelo nosso gerador. Esta compara√ß√£o ser√° avaliada ao comparar as sa√≠das com a pr√≥pria segmenta√ß√£o presente na base de dados ATM'22, feita por especialistas. Al√©m disso, ser√° calculado o coeficiente DICE (obtido a partir da precis√£o e *recall* da predi√ß√£o), tomando como refer√™ncia o artigo [[2]](#2), e considera-se tamb√©m calcular o tempo de processamento das redes U-Net e U-Net com *features* extra√≠dos pela nossa Pix2Pix, a fim de verificar se tamb√©m h√° uma otimiza√ß√£o neste quesito.

Ressalta-se que foram escolhidas duas fun√ß√µes de *loss* para esta tarefa: BCEWithLogitsLoss e DICELoss, tipicamente utilizadas em tarefas de segmenta√ß√£o de imagens m√©dicas.
Al√©m disso, para aproveitar os pesos iniciais da GAN para a tarefa de segmenta√ß√£o, s√£o feitas tr√™s varia√ß√µes no processo de *fine-tunning*:
1. Retreina-se todos os pesos da arquitetura, utilizando o conhecimento adquirido pela GAN apenas como uma inicializa√ß√£o n√£o aleat√≥ria para o treinamento da rede de segmenta√ß√£o;
2. Congela-se apenas a parte da rede codificadora do gerador, retreinando somente o decodificador;
3. Congela-se todas as camadas do gerador, com excess√£o da √∫ltima camada.

Por fim, √© importante destacar o caminho a ser seguido para a avalia√ß√£o da rede generativa para as sa√≠das em 3D, caso seja poss√≠vel implement√°-las dentro do prazo do projeto. Para esta aplica√ß√£o, gerar√≠amos um volume sint√©tico e passar√≠amos esta sa√≠da pela rede de segmenta√ß√£o *medpseg* [[10]](#10). Feito isso, comparar√≠amos as vias a√©reas segmentadas com o *ground-truth* estabelecido na pr√≥pria base de dados ATM'22.

### Cronograma
O projeto ser√° implementado seguindo o seguinte fluxo l√≥gico:

![Fluxo l√≥gico das ativaidades para desenvolvimento da PulmoNet.](figs/fluxo_logico.png?raw=true)

*Figura 12: Fluxo l√≥gico das ativaidades para desenvolvimento da PulmoNet.*

Dado este fluxo, estipulamos o seguinte cronograma para desenvolvimento do projeto:

| N¬∫ da Tarefa | Descri√ß√£o                                                                 | Data Prevista de Finaliza√ß√£o | Semanas Entre Etapas |
|--------------|---------------------------------------------------------------------------|------------------------------|----------------------|
| 1            | Leitura de artigos, familiariza√ß√£o com a base de dados e GANs             | 10/09                        |                      |
| 2            | Primeira vers√£o da GAN (inspirada no artigo de refer√™ncia)                | 24/09                        | 2 semanas            |
| 3            | Estrutura de avalia√ß√£o bem delimitada                                     | 07/10                        | 2 semanas            |
| 4            | E2                                                                        | 08/10                        | 1 dia                |
| 5            | Primeiros resultados com imagens segmentadas e valores para valida√ß√£o     | 15/10                        | 1 semana             |
| 6            | Fine-tuning e aperfei√ßoamento do modelo                                   | 29/10                        | 2 semanas            |
| 7            | Evoluir para redes 3D ou continuar aperfei√ßoando o modelo                 | 05/11                        | 1 semana             |
| 8            | E3                                                                        | 25/11                        | 3 semanas            |



### Ambiente Computacional
> TODO: Falar sobre a m√°quina usada para treinar a GAN (quantidade de mem√≥ria, tipo de GPU etc) e para treinar a rede de segmenta√ß√£o

Os modelos da GAN foram treinados em uma m√°quina com uma GPU NVIDIA GeForce RTX 3060.
J√° o modelo da rede de segmenta√ß√£o, para o teste de utilidade, foi treinado em um computador pessoal que tinha uma GPU 	NVIDIA GeForce RTX 3050, 4G de mem√≥ria de GPU, 16G de mem√≥ria RAM e processador Intel I5 de 12¬™ gera√ß√£o.


## Experimentos, Resultados e Discuss√£o dos Resultados
> TODO: Atualizar com dados da E3

Para a entrega parcial do projeto (E2), j√° foi feito um estudo de artigos na literatura no contexto do nosso projeto. Al√©m disso, seguindo o cronograma do projeto, tamb√©m foi finalizada a etapa de an√°lise da base de dados e a defini√ß√£o das etapas de pr√©-processamento, conforme j√° discutido brevemente na se√ß√£o sobre a base de dados. Mais ainda, tamb√©m foi realizada a implementa√ß√£o da arquitetura inicial das GANs escolhidas para o projeto, tomando como base o desenvolvimento em [[1]](#1), e iniciou-se a etapa de treinamento deste modelo.

Atualmente, estamos enfrentando dificuldades nesta etapa de treinamento, j√° que notamos que o discriminador estava ficando muito bom r√°pido demais, n√£o permitindo que o gerador conseguisse avan√ßar em seu aprendizado. Para solucionar este problema, tentaremos usar a estrat√©gia de atualizar a *loss* do gerador com mais frequ√™ncia do que a do discriminador (a priori, atualizaremos a loss do discriminador a cada 3 batches de atualiza√ß√£o da loss do gerador).

O resultado atual do nosso treinamento √© apresentado na figura abaixo. Nota-se que a sa√≠da do gerador ainda est√° distante do esperado e precisa ser aprimorada.

![Fatia original, fatia segmentada, sa√≠da do gerador e sa√≠da do discriminador.](figs/resultado_parcial_e2.jpeg?raw=true)

*Figura 13: Fatia original, fatia segmentada, sa√≠da do gerador e sa√≠da do discriminador.*

Ademais outros problemas que estamos enfrentando durante a etapa do treinamento tratam do tamanho da nossa base de dados, que √© bem grande e resulta em um processamento demorado, e o uso de recursos em GPU.

## Conclus√£o
> TODO: Atualizar com dados da E3

O projeto da rede PulmoNet busca a gera√ß√£o de fatias de CTs pulmonares a partir de m√°scaras bin√°rias, em duas dimens√µes, baseada em GANs. Esta rede utiliza uma arquitetura Pix2Pix para o gerador e uma PatchGAN para o discriminador. S√£o usados dados da base p√∫blica ATM'22, cujos dados correspondem a volumes pulmonares de tomografias e segmenta√ß√µes das vias a√©reas feitas por especialistas. Para a avalia√ß√£o da qualidade da rede, prop√µe-se m√©todos qualitativos, quantitativos e an√°lises de utilidade.

Seguindo o cronograma do projeto, as etapas at√© a entrega E2 foram cumpridas, de maneira que estamos atualmente na fase de treinamento do modelo e implementa√ß√£o dos m√©todos de avalia√ß√£o. No caso do treinamento, estamos enfrentando algumas dificuldades que est√£o afetando a qualidade das sa√≠das da rede, principalmente no quesito da velocidade de aprendizado do discriminador frente a do gerador.

Os pr√≥ximos passos do projeto tratam da finaliza√ß√£o do treinamento do modelo, an√°lise das m√©tricas de avalia√ß√£o e fine-tunning e aperfei√ßoamento do modelo. Caso tenhamos tempo dispon√≠vel, buscaremos a gera√ß√£o de volumes 3D de CTs pulmonares.

### Pr√≥ximos Passos
> TODO

## Refer√™ncias Bibliogr√°ficas

<a id="1">[1]</a> : Jos√© Mendes et al., Lung CT image synthesis using GANs, Expert Systems with Applications, vol. 215, 2023, pp. 119350., https://www.sciencedirect.com/science/article/pii/S0957417422023685.

<a id="2">[2]</a> : Minghui Zhang et al., Multi-site, Multi-domain Airway Tree Modeling (ATM'22): A Public Benchmark for Pulmonary Airway Segmentation, https://arxiv.org/abs/2303.05745.

<a id="3">[3]</a> :  Jacopo Lenkowicz et al., A deep learning approach to generate synthetic CT in low field MR-guided radiotherapy for lung cases, Radiotherapy and Oncology, vol. 176, 2022, pp. 31-38, https://www.sciencedirect.com/science/article/pii/S0167814022042608.

<a id="4">[4]</a> : Swati P. Pawar and Sanjay N. Talbar, LungSeg-Net: Lung field segmentation using generative adversarial network, Biomedical Signal Processing and Control, vol. 64, 2021, 102296, https://www.sciencedirect.com/science/article/pii/S1746809420304158.

<a id="5">[5]</a> : Tekatli, Hil√¢l et al. ‚ÄúArtificial intelligence-assisted quantitative CT analysis of airway changes following SABR for central lung tumors.‚Äù Radiotherapy and oncology : journal of the European Society for Therapeutic Radiology and Oncology vol. 198 (2024): 110376. doi:10.1016/j.radonc.2024.110376, https://pubmed.ncbi.nlm.nih.gov/38857700/

<a id="6">[6]</a> : Zhang, Ling et al. ‚ÄúGeneralizing Deep Learning for Medical Image Segmentation to Unseen Domains via Deep Stacked Transformation.‚Äù IEEE transactions on medical imaging vol. 39,7 (2020): 2531-2540. doi:10.1109/TMI.2020.2973595, https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7393676/

<a id="7">[7]</a> : Hofmanninger, J., Prayer, F., Pan, J. et al. Automatic lung segmentation in routine imaging is primarily a data diversity problem, not a methodology problem. Eur Radiol Exp 4, 50 (2020). https://doi.org/10.1186/s41747-020-00173-2

<a id="8">[8]</a> : Isola, P., Zhu, J. Y., Zhou, T., & Efros, A. A. (2017). Image-to-image translation with conditional adversarial networks. In Proceedings - 30th IEEE conference on computer vision and pattern recognition, CVPR 2017. http://dx.doi.org/10.1109/CVPR.2017. 632, arXiv:1611.07004.

<a id="9">[9]</a> : Radford, A., Metz, L., and Chintala, S., ‚ÄúUnsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks‚Äù, <i>arXiv e-prints</i>, Art. no. arXiv:1511.06434, 2015. doi:10.48550/arXiv.1511.06434.

<a id="10">[10]</a> : Carmo, D. S., ‚ÄúMEDPSeg: Hierarchical polymorphic multitask learning for the segmentation of ground-glass opacities, consolidation, and pulmonary structures on computed tomography‚Äù, <i>arXiv e-prints</i>, Art. no. arXiv:2312.02365, 2023. doi:10.48550/arXiv.2312.02365.

Documento com as refer√™ncias extras identificadas: https://docs.google.com/document/d/1uatPj6byVIEVrvMuvbII6J6-5usOjf8RLrSxLHJ8u58/edit?usp=sharing

# How To Run
Como uma observa√ß√£o adicional, incluimos uma descri√ß√£o de como executar as fun√ß√µes propostas neste projeto.

**Processamento da base de dados:**

`1.` Baixar a base de dados ATM'22 na internet

`2.` Fazer a leitura inicial dos dados por meio da classe `rawCTData`


**Treinamento da GAN:**

1. Configurar par√¢metros do modelo no arquivo `config.yaml` e a localiza√ß√£o da pasta com os dados processados.

2. Executar comando em seu terminal:

```
py training_pipeline.py
```

3. Selecionar o arquivo YAML de configura√ß√£o desejado:

'''
 config.yaml
'''

**Obten√ß√£o das m√©tricas da GAN:**

`1.` Configurar par√¢metros do modelo no arquivo `config_eval.yaml` e a localiza√ß√£o da pasta com os dados processados.

`2.` Executar comando em seu terminal:

```
test_pipeline.py config_eval.yaml
```

**Treinamento da rede de segmenta√ß√£o:**

`1.` Configurar par√¢metros do modelo no arquivo `config_segmentation.yaml` e a localiza√ß√£o da pasta com os dados processados.

`2.` Executar comando em seu terminal:

```
segmentation_pipeline.py config_segmentation.yaml
```
