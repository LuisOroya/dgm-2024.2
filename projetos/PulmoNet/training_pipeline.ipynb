{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook para treinar a GAN para síntese de imagens CT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definições iniciais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import trange\n",
    "import random\n",
    "random.seed(5)\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import lungCTData\n",
    "from model import Generator, Discriminator\n",
    "from main import run_train_epoch, run_validation_epoch, valid_on_the_fly\n",
    "from utils import clean_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definições do treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dados\n",
    "start_point_train_data = 0\n",
    "end_point_train_data = 10000\n",
    "start_point_validation_data = 10000\n",
    "end_point_validation_data = 10500\n",
    "#bacthes\n",
    "batch_size_train = 20\n",
    "batch_size_validation = 8\n",
    "#learning param\n",
    "n_epochs = 200\n",
    "initial_lr = 0.0002\n",
    "epoch_to_switch_to_lr_scheduler = 100\n",
    "#loss\n",
    "criterion = torch.nn.BCELoss()\n",
    "regularization = 10\n",
    "steps_to_complete_bfr_upd_disc = 1\n",
    "steps_to_complete_bfr_upd_gen = 1\n",
    "#safe save\n",
    "step_to_safe_save_models = 10\n",
    "#save results directory\n",
    "new_model = True\n",
    "dir_save_results = './model_thr_25k/'\n",
    "dir_save_models = dir_save_results+'models/'\n",
    "dir_save_example = dir_save_results+'examples/'\n",
    "name_model = 'model_thr_25k'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data_folder = '/mnt/shared/ctdata_thr25'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = lungCTData(processed_data_folder=processed_data_folder,mode='train',start=start_point_train_data,end=end_point_train_data)\n",
    "dataset_validation = lungCTData(processed_data_folder=processed_data_folder,mode='train',start=start_point_validation_data,end=end_point_validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader_train = DataLoader(dataset_train, batch_size=batch_size_train, shuffle=True)\n",
    "data_loader_validation = DataLoader(dataset_validation, batch_size=batch_size_validation, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = Generator().to(device)\n",
    "disc = Discriminator().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_opt = torch.optim.Adam(gen.parameters(), lr=initial_lr, betas=(0.5, 0.999))\n",
    "disc_opt = torch.optim.Adam(disc.parameters(), lr=initial_lr, betas=(0.5, 0.999))\n",
    "gen_scheduler = torch.optim.lr_scheduler.LinearLR(gen_opt, start_factor=1.0, end_factor=0.0, total_iters=50)\n",
    "disc_scheduler = torch.optim.lr_scheduler.LinearLR(disc_opt, start_factor=1.0, end_factor=0.0, total_iters=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_loss_train_gen_list = []\n",
    "mean_loss_validation_gen_list = []\n",
    "mean_loss_train_disc_list = []\n",
    "mean_loss_validation_disc_list = []\n",
    "save_count_idx = 0\n",
    "\n",
    "os.makedirs(dir_save_results, exist_ok=True)\n",
    "if new_model == True:\n",
    "    clean_directory(dir_save_results)\n",
    "os.makedirs(dir_save_models, exist_ok=True)\n",
    "os.makedirs(dir_save_example, exist_ok=True)\n",
    "if new_model == True:\n",
    "    with open(dir_save_results+'losses.csv', 'w', newline='') as csvfile:\n",
    "        fieldnames = ['LossGenTrain', 'LossDiscTrain', 'LossGenVal', 'LoddDiscVal']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(n_epochs):\n",
    "\n",
    "    loss_train_gen, loss_train_disc = run_train_epoch(gen=gen, disc=disc, criterion=criterion, regularization=regularization, \n",
    "                                        data_loader=data_loader_train, disc_opt=disc_opt, gen_opt=gen_opt, \n",
    "                                        epoch=epoch, steps_to_complete_bfr_upd_disc=steps_to_complete_bfr_upd_disc, \n",
    "                                        steps_to_complete_bfr_upd_gen=steps_to_complete_bfr_upd_gen, device=device)\n",
    "\n",
    "    mean_loss_train_gen_list.append(loss_train_gen)\n",
    "    mean_loss_train_disc_list.append(loss_train_disc)\n",
    "\n",
    "    loss_validation_gen, loss_validation_disc = run_validation_epoch(gen=gen, disc=disc, criterion=criterion, regularization=regularization, \n",
    "                                                data_loader=data_loader_validation, epoch=epoch, device=device)\n",
    "\n",
    "    mean_loss_validation_gen_list.append(loss_validation_gen)\n",
    "    mean_loss_validation_disc_list.append(loss_validation_disc)\n",
    "\n",
    "    valid_on_the_fly(gen=gen, disc=disc, data_loader=data_loader_validation, epoch=epoch,save_dir=dir_save_example,device=device)\n",
    "\n",
    "    if epoch%step_to_safe_save_models == 0:\n",
    "        torch.save(gen.state_dict(), f\"{dir_save_models}{name_model}_last_lr_{gen_scheduler.get_last_lr()[0]}_savesafe.pt\")\n",
    "        torch.save(disc.state_dict(), f\"{dir_save_models}{name_model}_last_lr_{disc_scheduler.get_last_lr()[0]}_savesafe.pt\")\n",
    "        with open(dir_save_results+'losses.csv', mode='a', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            for i in range(save_count_idx,epoch+1):\n",
    "                writer.writerow([mean_loss_train_gen_list[i], mean_loss_train_disc_list[i], \n",
    "                                mean_loss_validation_gen_list[i],mean_loss_validation_disc_list[i]])\n",
    "        save_count_idx = epoch+1\n",
    "\n",
    "    if epoch >= epoch_to_switch_to_lr_scheduler:\n",
    "        gen_scheduler.step()\n",
    "        disc_scheduler.setp()\n",
    "        print(\"Current learning rate: gen: \", gen_scheduler.get_last_lr()[0], \" disc: \", disc_scheduler.get_last_lr()[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(gen.state_dict(), f\"{dir_save_models}{name_model}_gen_trained.pt\")\n",
    "torch.save(disc.state_dict(), f\"{dir_save_models}{name_model}_disc_trained.pt\")\n",
    "if save_count_idx < n_epochs:\n",
    "    with open(dir_save_results+'losses.csv', mode='a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        for i in range(save_count_idx,n_epochs):\n",
    "            writer.writerow([mean_loss_train_gen_list[i], mean_loss_train_disc_list[i], \n",
    "                            mean_loss_validation_gen_list[i],mean_loss_validation_disc_list[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,2,figsize=(14,4))\n",
    "ax[0].plot(mean_loss_train_gen_list, label= 'Train')\n",
    "ax[0].plot(mean_loss_validation_gen_list, label='Validation')\n",
    "ax[1].plot(mean_loss_train_disc_list,label='Train')\n",
    "ax[1].plot(mean_loss_validation_disc_list,label='Validation')\n",
    "ax[0].legend(loc='upper right')\n",
    "ax[1].legend(loc='upper right')\n",
    "ax[0].set_title('Generator')\n",
    "ax[1].set_title('Discriminator')\n",
    "ax[0].set_xlabel('Epochs')\n",
    "ax[1].set_xlabel('Epochs')\n",
    "plt.savefig(dir_save_results+'_losses_evolution.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pulmonet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
